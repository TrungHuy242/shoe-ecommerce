"""
Footy AI Assistant v2.0 - Intelligent Shopping Assistant for FootFashion
N√¢ng c·∫•p v·ªõi Gemini Pro v√† context-aware product recommendations
"""

import os
import re
import time
from typing import Dict, List, Any, Optional, Tuple
from collections import deque
import google.generativeai as genai
from django.conf import settings
from django.db.models import Q
from django.utils import timezone
from django.core.cache import cache
from difflib import SequenceMatcher
import logging

# Import Django models
from ..models import Product, Brand, Category, Gender, Size, Color, Promotion, Order

logger = logging.getLogger(__name__)

# Configure Gemini API
GEMINI_API_KEY = getattr(settings, 'GEMINI_API_KEY', None) or os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)


class ConversationMemory:
    """Qu·∫£n l√Ω ng·ªØ c·∫£nh h·ªôi tho·∫°i trong 5 l∆∞·ª£t g·∫ßn nh·∫•t"""
    
    def __init__(self, max_size: int = 5):
        self.memories = {}  # user_id -> deque of conversations
        self.max_size = max_size
    
    def add_conversation(self, user_id: str, message: str, response: str, intent: str):
        """Th√™m cu·ªôc h·ªôi tho·∫°i v√†o memory"""
        if user_id not in self.memories:
            self.memories[user_id] = deque(maxlen=self.max_size)
        
        conversation = {
            'message': message,
            'response': response,
            'intent': intent,
            'timestamp': timezone.now().isoformat()
        }
        self.memories[user_id].append(conversation)
    
    def get_context(self, user_id: str) -> List[Dict]:
        """L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i g·∫ßn nh·∫•t"""
        return list(self.memories.get(user_id, []))
    
    def clear_context(self, user_id: str):
        """X√≥a ng·ªØ c·∫£nh c·ªßa user"""
        if user_id in self.memories:
            del self.memories[user_id]


class ProductContextBuilder:
    """X√¢y d·ª±ng context s·∫£n ph·∫©m t·ª´ database"""
    
    @staticmethod
    def get_products_context(limit: int = 15) -> str:
        """L·∫•y context s·∫£n ph·∫©m t·ª´ database - Optimized for speed"""
        try:
            # L·∫•y s·∫£n ph·∫©m v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß - Gi·∫£m limit ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
            products = Product.objects.select_related('brand', 'category', 'gender').prefetch_related(
                'sizes', 'colors', 'images'
            ).order_by('-sales_count', '-id')[:limit]  # ∆Øu ti√™n s·∫£n ph·∫©m b√°n ch·∫°y
            
            if not products.exists():
                return "Hi·ªán t·∫°i c·ª≠a h√†ng ch∆∞a c√≥ s·∫£n ph·∫©m n√†o."
            
            context_lines = []
            for product in products:
                # T·∫°o m√¥ t·∫£ ng·∫Øn g·ªçn cho t·ª´ng s·∫£n ph·∫©m - T·ªëi ∆∞u cho t·ªëc ƒë·ªô
                description_parts = []
                
                # T√™n v√† th∆∞∆°ng hi·ªáu
                description_parts.append(f"{product.name} - {product.brand.name}")
                
                # Gi√°
                price_formatted = f"{product.price:,.0f} VND"
                description_parts.append(f"Gi√°: {price_formatted}")
                
                # M√¥ t·∫£ ng·∫Øn - Gi·∫£m ƒë·ªô d√†i ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
                if product.description:
                    short_desc = product.description[:80].strip()  # Gi·∫£m t·ª´ 100 xu·ªëng 80
                    if len(product.description) > 80:
                        short_desc += "..."
                    description_parts.append(f"M√¥ t·∫£: {short_desc}")
                
                # Gi·ªõi t√≠nh
                if product.gender:
                    description_parts.append(f"Gi·ªõi t√≠nh: {product.gender.name}")
                
                # Sizes c√≥ s·∫µn - Gi·∫£m s·ªë l∆∞·ª£ng
                sizes = product.sizes.all()[:3]  # Gi·∫£m t·ª´ 5 xu·ªëng 3
                if sizes:
                    size_values = [str(size.value) for size in sizes]
                    description_parts.append(f"Sizes: {', '.join(size_values)}")
                
                # M√†u s·∫Øc c√≥ s·∫µn - Gi·∫£m s·ªë l∆∞·ª£ng
                colors = product.colors.all()[:2]  # Gi·∫£m t·ª´ 3 xu·ªëng 2
                if colors:
                    color_values = [color.value for color in colors]
                    description_parts.append(f"M√†u s·∫Øc: {', '.join(color_values)}")
                
                # S·ªë l∆∞·ª£ng b√°n ƒë∆∞·ª£c
                if product.sales_count > 0:
                    description_parts.append(f"ƒê√£ b√°n: {product.sales_count} ƒë√¥i")
                
                # Gh√©p th√†nh m·ªôt d√≤ng
                product_line = " | ".join(description_parts)
                context_lines.append(f"- {product_line}")
            
            return "\n".join(context_lines)
            
        except Exception as e:
            logger.error(f"Error building product context: {e}")
            return "Kh√¥ng th·ªÉ t·∫£i th√¥ng tin s·∫£n ph·∫©m."
    
    @staticmethod
    def get_promotions_context() -> str:
        """L·∫•y context khuy·∫øn m√£i - Optimized for speed"""
        try:
            now = timezone.now()
            promotions = Promotion.objects.filter(
                is_active=True,
                start_date__lte=now,
                end_date__gte=now
            ).order_by('-discount_percentage')[:5]  # Gi·∫£m t·ª´ 10 xu·ªëng 5
            
            if not promotions.exists():
                return "Hi·ªán t·∫°i kh√¥ng c√≥ khuy·∫øn m√£i n√†o."
            
            context_lines = []
            for promo in promotions:
                end_date_str = promo.end_date.strftime('%d/%m/%Y') if promo.end_date else "Kh√¥ng gi·ªõi h·∫°n"
                context_lines.append(
                    f"- M√£: {promo.code} | Gi·∫£m {promo.discount_percentage}% | H·∫øt h·∫°n: {end_date_str}"
                )
            
            return "\n".join(context_lines)
            
        except Exception as e:
            logger.error(f"Error building promotions context: {e}")
            return "Kh√¥ng th·ªÉ t·∫£i th√¥ng tin khuy·∫øn m√£i."


class AdvancedNLPProcessor:
    """X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n n√¢ng cao"""
    
    def __init__(self):
        # T·ª´ ƒë·ªìng nghƒ©a v√† bi·∫øn th·ªÉ - Enhanced for natural language
        self.synonyms = {
            'gi√†y': ['giay', 'gi√†y d√©p', 'shoe', 'shoes', 'sneaker', 'boot', 'ƒë√¥i gi√†y', 'c√°i gi√†y'],
            'd√©p': ['dep', 'sandals', 'flip-flop', 'slipper', 'ƒë√¥i d√©p', 'c√°i d√©p'],
            'nike': ['nike', 'nike air', 'air max', 'jordan'],
            'adidas': ['adidas', 'adidas originals', 'ultraboost'],
            'puma': ['puma', 'puma suede'],
            'vans': ['vans', 'vans old skool'],
            'converse': ['converse', 'chuck taylor', 'all star'],
            'nam': ['nam', 'male', 'men', 'ƒë√†n √¥ng', 'con trai'],
            'n·ªØ': ['n·ªØ', 'nu', 'female', 'women', 'ph·ª• n·ªØ', 'con g√°i'],
            'gi√°': ['gia', 'price', 'cost', 'ti·ªÅn', 'gi√° c·∫£'],
            'r·∫ª': ['re', 'cheap', 'affordable', 'gi√° r·∫ª', 'h·ª£p l√Ω'],
            'ƒë·∫Øt': ['dat', 'expensive', 'gi√° cao', 'm·∫Øc'],
            'size': ['s·ªë', 'k√≠ch c·ª°', 'size', 'c·ª°', 's·ªë gi√†y'],
            'm√†u': ['mau', 'color', 'colour', 'm√†u s·∫Øc'],
            'ƒëen': ['den', 'black'],
            'tr·∫Øng': ['trang', 'white'],
            'ƒë·ªè': ['do', 'red'],
            'xanh': ['blue', 'green'],
            't√¨m': ['tim', 'find', 'search', 'look for', 't√¨m ki·∫øm'],
            'mua': ['buy', 'purchase', 'order', 'mua s·∫Øm'],
            'xem': ['see', 'view', 'look at', 'nh√¨n', 'coi'],
            'g·ª£i √Ω': ['goi y', 'suggest', 'recommend', 'advise', 'ƒë·ªÅ xu·∫•t'],
            'khuy·∫øn m√£i': ['khuyen mai', 'promotion', 'sale', 'discount', '∆∞u ƒë√£i'],
            'gi·∫£m gi√°': ['giam gia', 'discount', 'off', 'sale', 'gi·∫£m'],
            'ƒë∆°n h√†ng': ['don hang', 'order', 'orders', 'ƒë∆°n'],
            'c·ªßa t√¥i': ['cua toi', 'my', 'mine', 'c·ªßa m√¨nh'],
            'g·∫ßn ƒë√¢y': ['gan day', 'recent', 'lately', 'm·ªõi ƒë√¢y'],
            't·ªët': ['tot', 'good', 'nice', 'great', 'ƒë·∫πp', 'hay'],
            'ƒë·∫πp': ['dep', 'beautiful', 'pretty', 'nice', 't·ªët'],
            'hay': ['good', 'great', 'awesome', 't·ªët', 'ƒë·∫πp'],
            'c·∫ßn': ['need', 'want', 'require', 'mu·ªën'],
            'mu·ªën': ['want', 'need', 'desire', 'c·∫ßn'],
            'cho t√¥i': ['cho toi', 'give me', 'show me', 't√¥i mu·ªën'],
            'v√†i': ['some', 'a few', 'm·ªôt v√†i', 'm·ªôt s·ªë'],
            'm·ªôt s·ªë': ['some', 'several', 'v√†i', 'm·ªôt v√†i'],
            'h√¥m nay': ['hom nay', 'today', 'hi·ªán t·∫°i', 'b√¢y gi·ªù']
        }
        
        # T·ª´ kh√≥a c·∫£m x√∫c ti·∫øng Vi·ªát - Enhanced for Gen Z
        self.positive_words = [
            't·ªët', 'ƒë·∫πp', 'hay', 'tuy·ªát', 'ok', 'ƒë∆∞·ª£c', 'th√≠ch', 'y√™u', 'h√†i l√≤ng',
            'vui', 'h·∫°nh ph√∫c', 'th√∫ v·ªã', 'th√≠ch th√∫', 'c·∫£m ∆°n', 'thanks', 'perfect',
            'awesome', 'great', 'excellent', 'amazing', 'wonderful',
            'hot', 'hit', 'ngon', 'ch·∫•t', 'x·ªãn', 'ƒë·ªânh', 'pro', 'cool', 'nice',
            '·ªïn', 'ok', 'ƒë∆∞·ª£c', 'tuy·ªát v·ªùi', 'xu·∫•t s·∫Øc', 'tuy·ªát h·∫£o'
        ]
        self.negative_words = [
            't·ªá', 'x·∫•u', 'd·ªü', 'kh√¥ng th√≠ch', 'gh√©t', 'b·ª±c', 't·ª©c', 'kh√≥ ch·ªãu',
            'kh√¥ng h√†i l√≤ng', 'th·∫•t v·ªçng', 'bu·ªìn', 'lo l·∫Øng', 'kh√¥ng ok', 'bad',
            'terrible', 'awful', 'horrible', 'disappointed', 'angry',
            'ƒë·∫Øt', 'm·∫Øc', 'gi√° cao', 's·ª£ mau d∆°', 'kh√¥ng b·ªÅn', 'kh√¥ng √™m',
            'kh√≥ ch·ªãu', 'kh√¥ng ph√π h·ª£p', 'kh√¥ng v·ª´a', 'ch·∫≠t', 'r·ªông',
            'kh√¥ng c√≥', 'h·∫øt h√†ng', 'out of stock', 'sold out'
        ]
        self.urgent_words = [
            'g·∫•p', 'kh·∫©n c·∫•p', 'nhanh', 'ngay', 'l·∫≠p t·ª©c', 'urgent', 'asap',
            'immediately', 'quickly', 'fast', 'hurry'
        ]
        
        # Intent patterns v·ªõi confidence scores - Improved for natural language
        self.intent_patterns = {
            'greeting': [
                (r'\b(xin ch√†o|ch√†o|hello|hi|hey|xin ch[a√†]o)\b', 0.9),
                (r'\b(c√≥ ai|ai ƒë√≥|c√≥ ng∆∞·ªùi)\b', 0.8),
                (r'\b(start|b·∫Øt ƒë·∫ßu|begin)\b', 0.7),
                (r'\b(morning|afternoon|evening)\b', 0.6)
            ],
            'product_search': [
                # Natural language patterns
                (r'\b(t√¥i mu·ªën|t√¥i c·∫ßn|cho t√¥i|t√¨m|mua|xem|c√≥)\b.*\b(gi√†y|d√©p|sneaker|boot|sandal)\b', 0.9),
                (r'\b(gi√†y|d√©p|sneaker|boot|sandal)\b.*\b(nike|adidas|puma|vans|converse)\b', 0.9),
                (r'\b(nike|adidas|puma|vans|converse)\b', 0.8),
                (r'\b(nam|n·ªØ|unisex)\b.*\b(gi√†y|d√©p)\b', 0.8),
                (r'\b(size|m√†u|color|gi√°|price|r·∫ª|ƒë·∫Øt)\b', 0.7),
                (r'\b(d∆∞·ªõi|tr√™n|kho·∫£ng)\b.*\b(tri·ªáu|tr|k|vnd)\b', 0.8),
                (r'\b(gi√†y n√†o|d√©p n√†o|c√≥.*gi√†y|c√≥.*d√©p)\b', 0.7),
                (r'\b(ch·∫°y b·ªô|th·ªÉ thao|c√¥ng s·ªü|ƒëi l√†m|ƒëi ch∆°i|ƒëi h·ªçc)\b', 0.6),
                (r'\b(m·ªôt ƒë√¥i|v√†i ƒë√¥i|v√†i c√°i)\b.*\b(gi√†y|d√©p)\b', 0.6),
                (r'\b(√™m ch√¢n|nh·∫π ch√¢n|tho·∫£i m√°i|comfortable)\b', 0.6),
                (r'\b(ƒë·∫πp|t·ªët|hay|nice|good)\b.*\b(gi√†y|d√©p)\b', 0.6)
            ],
            'recommendation': [
                (r'\b(g·ª£i √Ω|ƒë·ªÅ xu·∫•t|recommend|suggest|n√™n mua|b√°n ch·∫°y|hot|trending)\b', 0.9),
                (r'\b(gi√†y n√†o|d√©p n√†o|s·∫£n ph·∫©m n√†o)\b.*\b(t·ªët|ƒë·∫πp|ch·∫•t l∆∞·ª£ng|b·ªÅn|hay)\b', 0.8),
                (r'\b(top|best|t·ªët nh·∫•t|hay nh·∫•t|ƒë·∫πp nh·∫•t)\b', 0.8),
                (r'\b(ph√π h·ª£p|h·ª£p v·ªõi)\b', 0.7),
                (r'\b(popular|trending|favorite)\b', 0.7),
                (r'\b(g·ª£i √Ω cho|suggest for|recommend for)\b', 0.8),
                (r'\b(c√≥ g·ª£i √Ω|c√≥ suggest|c√≥ recommend)\b', 0.8),
                (r'\b(ƒëi l√†m|ƒëi h·ªçc|c√¥ng s·ªü|th·ªÉ thao)\b.*\b(g·ª£i √Ω|suggest)\b', 0.7)
            ],
            'promotion': [
                (r'\b(khuy·∫øn m√£i|gi·∫£m gi√°|sale|discount|voucher|m√£ gi·∫£m|coupon|∆∞u ƒë√£i)\b', 0.9),
                (r'\b(m√£|code|promo)\b', 0.8),
                (r'\b(gi·∫£m|discount|off)\b', 0.7),
                (r'\b(deal|offer|special)\b', 0.6),
                (r'\b(xem.*khuy·∫øn m√£i|xem.*sale|c√≥.*khuy·∫øn m√£i|c√≥.*sale)\b', 0.8),
                (r'\b(h√¥m nay|today|hi·ªán t·∫°i|now)\b.*\b(khuy·∫øn m√£i|sale|gi·∫£m gi√°)\b', 0.7),
                (r'\b(c√≥.*khuy·∫øn m√£i|c√≥.*sale|c√≥.*gi·∫£m gi√°)\b', 0.8),
                (r'\b(khuy·∫øn m√£i.*h√¥m nay|sale.*h√¥m nay|gi·∫£m gi√°.*h√¥m nay)\b', 0.8)
            ],
            'order_status': [
                (r'\b(ƒë∆°n h√†ng|order|giao h√†ng|v·∫≠n chuy·ªÉn|ship|tracking|theo d√µi)\b', 0.9),
                (r'\b(tr·∫°ng th√°i|t√¨nh tr·∫°ng|status)\b', 0.8),
                (r'\b(khi n√†o|bao gi·ªù|when)\b.*\b(giao|deliver)\b', 0.8),
                (r'\b(tracking|shipment|delivery)\b', 0.7),
                (r'\b(xem.*ƒë∆°n h√†ng|xem.*order|c·ªßa t√¥i|c·ªßa m√¨nh)\b', 0.8),
                (r'\b(g·∫ßn ƒë√¢y|recent|m·ªõi nh·∫•t|latest)\b.*\b(ƒë∆°n h√†ng|order)\b', 0.7)
            ],
            'help': [
                (r'\b(gi√∫p|help|h∆∞·ªõng d·∫´n|h·ªó tr·ª£|support|tr·ª£ gi√∫p)\b', 0.9),
                (r'\b(l√†m sao|how|nh∆∞ th·∫ø n√†o)\b', 0.8),
                (r'\b(help|h·ªó tr·ª£|guide)\b', 0.7),
                (r'\b(tutorial|instruction|manual)\b', 0.6),
                (r'\b(kh√¥ng bi·∫øt|confused|b·ªëi r·ªëi)\b', 0.7)
            ],
            'order_change_request': [
                (r'\b(ƒë·ªïi|thay ƒë·ªïi|change|swap)\b.*\b(size|m√†u|color|ƒë∆°n h√†ng|order)\b', 0.9),
                (r'\b(ƒë·∫∑t|order)\b.*\b(h√¥m qua|yesterday|tr∆∞·ªõc)\b.*\b(ƒë·ªïi|change|thay)\b', 0.9),
                (r'\b(mu·ªën ƒë·ªïi|want to change|thay ƒë·ªïi)\b', 0.8),
                (r'\b(ƒë·ªïi sang|change to|switch to)\b', 0.8),
                (r'\b(size|m√†u|color)\b.*\b(kh√°c|different|other)\b', 0.7)
            ]
        }
    
    def normalize_text(self, text: str) -> str:
        """Chu·∫©n h√≥a text: lowercase, remove accents, expand synonyms"""
        text = text.lower().strip()
        
        # Expand synonyms
        for key, synonyms in self.synonyms.items():
            for synonym in synonyms:
                if synonym in text:
                    text = text.replace(synonym, key)
        
        return text
    
    def fuzzy_match(self, text: str, patterns: List[Tuple[str, float]]) -> Tuple[str, float]:
        """Fuzzy matching v·ªõi confidence score"""
        best_intent = 'unknown'
        best_score = 0.0
        
        normalized_text = self.normalize_text(text)
        
        for intent, pattern_list in self.intent_patterns.items():
            for pattern, base_confidence in pattern_list:
                if re.search(pattern, normalized_text):
                    # Calculate fuzzy score
                    match = re.search(pattern, normalized_text)
                    if match:
                        matched_text = match.group()
                        similarity = SequenceMatcher(None, matched_text, normalized_text).ratio()
                        final_score = base_confidence * similarity
                        
                        if final_score > best_score:
                            best_score = final_score
                            best_intent = intent
        
        return best_intent, best_score
    
    def extract_entities(self, text: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t entities t·ª´ text"""
        entities = {}
        normalized_text = self.normalize_text(text)
        
        # Extract brand
        brands = ['nike', 'adidas', 'puma', 'vans', 'converse']
        for brand in brands:
            if brand in normalized_text:
                entities['brand'] = brand.capitalize()
                break
        
        # Extract gender
        if 'nam' in normalized_text and 'n·ªØ' not in normalized_text:
            entities['gender'] = 'Nam'
        elif 'n·ªØ' in normalized_text or 'nu' in normalized_text:
            entities['gender'] = 'N·ªØ'
        elif 'unisex' in normalized_text:
            entities['gender'] = 'Unisex'
        
        # Extract size
        size_patterns = [
            r'size\s*(\d{2})',
            r'(\d{2})\s*(size|s·ªë)',
            r's·ªë\s*(\d{2})'
        ]
        for pattern in size_patterns:
            match = re.search(pattern, normalized_text)
            if match:
                entities['size'] = match.group(1)
                break
        
        # Extract color
        colors = ['ƒëen', 'tr·∫Øng', 'ƒë·ªè', 'xanh', 'v√†ng', 'n√¢u', 'h·ªìng', 'x√°m', 'cam', 't√≠m']
        for color in colors:
            if color in normalized_text:
                entities['color'] = color
                break
        
        # Extract price range
        price_patterns = [
            r'd∆∞·ªõi\s*(\d+)\s*(tri·ªáu|tr|k|vnd)',
            r'(\d+)\s*(tri·ªáu|tr|k|vnd)\s*tr·ªü xu·ªëng',
            r'√≠t h∆°n\s*(\d+)\s*(tri·ªáu|tr|k|vnd)'
        ]
        for pattern in price_patterns:
            match = re.search(pattern, normalized_text)
            if match:
                amount = int(match.group(1))
                unit = match.group(2)
                if 'tri·ªáu' in unit or 'tr' in unit:
                    entities['max_price'] = amount * 1000000
                elif 'k' in unit:
                    entities['max_price'] = amount * 1000
                elif 'vnd' in unit:
                    entities['max_price'] = amount
                break
        
        return entities


class SentimentAnalyzer:
    """Ph√¢n t√≠ch c·∫£m x√∫c ng∆∞·ªùi d√πng n√¢ng cao"""
    
    def __init__(self):
        # T·ª´ kh√≥a c·∫£m x√∫c ti·∫øng Vi·ªát
        self.positive_words = [
            't·ªët', 'ƒë·∫πp', 'hay', 'tuy·ªát', 'ok', 'ƒë∆∞·ª£c', 'th√≠ch', 'y√™u', 'h√†i l√≤ng',
            'vui', 'h·∫°nh ph√∫c', 'th√∫ v·ªã', 'th√≠ch th√∫', 'c·∫£m ∆°n', 'thanks', 'perfect',
            'awesome', 'great', 'excellent', 'amazing', 'wonderful'
        ]
        self.negative_words = [
            't·ªá', 'x·∫•u', 'd·ªü', 'kh√¥ng th√≠ch', 'gh√©t', 'b·ª±c', 't·ª©c', 'kh√≥ ch·ªãu',
            'kh√¥ng h√†i l√≤ng', 'th·∫•t v·ªçng', 'bu·ªìn', 'lo l·∫Øng', 'kh√¥ng ok', 'bad',
            'terrible', 'awful', 'horrible', 'disappointed', 'angry'
        ]
        self.urgent_words = [
            'g·∫•p', 'kh·∫©n c·∫•p', 'nhanh', 'ngay', 'l·∫≠p t·ª©c', 'urgent', 'asap',
            'immediately', 'quickly', 'fast', 'hurry'
        ]
    
    def analyze_sentiment(self, message: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ tin nh·∫Øn"""
        message_lower = message.lower()
        
        # ƒê·∫øm t·ª´ t√≠ch c·ª±c v√† ti√™u c·ª±c
        positive_count = sum(1 for word in self.positive_words if word in message_lower)
        negative_count = sum(1 for word in self.negative_words if word in message_lower)
        urgent_count = sum(1 for word in self.urgent_words if word in message_lower)
        
        # X√°c ƒë·ªãnh sentiment
        if positive_count > negative_count:
            sentiment = 'positive'
        elif negative_count > positive_count:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        # X√°c ƒë·ªãnh urgency
        is_urgent = urgent_count > 0 or '!' in message or '?' in message
        
        return {
            'sentiment': sentiment,
            'confidence': max(positive_count, negative_count) / len(message.split()),
            'is_urgent': is_urgent,
            'positive_words': positive_count,
            'negative_words': negative_count
        }


class FootyAI:
    """AI Shopping Assistant "Footy" cho FootFashion - Advanced Version"""
    
    def __init__(self):
        self.model = None
        self.memory = ConversationMemory()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.nlp_processor = AdvancedNLPProcessor()
        self.context_builder = ProductContextBuilder()
        
        # Initialize Gemini model with proper API key
        self._initialize_gemini_model()
    
    def _initialize_gemini_model(self):
        """Initialize Gemini model with proper API key - Optimized for speed"""
        try:
            # Load API key directly from .env file
            from pathlib import Path
            from dotenv import load_dotenv
            
            # Get project root directory
            project_root = Path(__file__).resolve().parent.parent.parent.parent
            env_path = project_root / '.env'
            
            # Load .env file
            load_dotenv(env_path)
            
            # Get API key
            api_key = os.getenv('GEMINI_API_KEY')
            
            if api_key:
                genai.configure(api_key=api_key)
                # S·ª≠ d·ª•ng Gemini 2.5 Flash - Model nhanh nh·∫•t v√† m·∫°nh nh·∫•t hi·ªán t·∫°i
                self.model = genai.GenerativeModel('gemini-2.5-flash')
                logger.info("Gemini 2.5 Flash model initialized successfully - Optimized for speed")
            else:
                logger.warning("GEMINI_API_KEY not found, Gemini model not initialized")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini 2.5 Flash model: {e}")
            # Fallback to Pro model if Flash is not available
            try:
                if api_key:
                    genai.configure(api_key=api_key)
                    self.model = genai.GenerativeModel('gemini-2.5-pro')
                    logger.info("Fallback to Gemini 2.5 Pro model")
            except Exception as fallback_error:
                logger.error(f"Fallback to Pro model also failed: {fallback_error}")
                # Final fallback to 1.5 Pro
            try:
                if api_key:
                    genai.configure(api_key=api_key)
                    self.model = genai.GenerativeModel('gemini-1.5-pro-latest')
                    logger.info("Fallback to Gemini 1.5 Pro Latest model")
            except Exception as fallback_error:
                logger.error(f"Fallback model also failed: {fallback_error}")
    
    def detect_intent(self, message: str, context: List[Dict] = None) -> Tuple[str, float]:
        """
        Nh·∫≠n di·ªán √Ω ƒë·ªãnh ng∆∞·ªùi d√πng v·ªõi fuzzy matching v√† confidence score
        Enhanced context awareness for follow-up questions
        Returns: (intent, confidence_score)
        """
        message_lower = message.lower()
        
        # Enhanced context analysis for follow-up questions
        if context and len(context) > 0:
            last_conversation = context[-1]
            last_intent = last_conversation.get('intent', '')
            last_message = last_conversation.get('message', '').lower()
            
            # Follow-up question patterns
            follow_up_patterns = {
                'product_search': [
                    # Brand/type follow-ups
                    (r'\b(c√≤n|c√≥|th√™m)\b.*\b(th∆∞∆°ng hi·ªáu|brand|h√£ng|nike|adidas|puma|vans|converse)\b', 0.9),
                    (r'\b(th∆∞∆°ng hi·ªáu|brand|h√£ng)\b.*\b(kh√°c|kh√°c kh√¥ng|n√†o kh√°c)\b', 0.9),
                    (r'\b(c√≤n|c√≥)\b.*\b(th∆∞∆°ng hi·ªáu|brand|h√£ng)\b.*\b(kh√°c|n√†o)\b', 0.9),
                    
                    # Size/color follow-ups
                    (r'\b(c√≥|c√≤n)\b.*\b(size|m√†u|color|m√†u s·∫Øc)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(size|m√†u|color)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    
                    # Price follow-ups
                    (r'\b(c√≥|c√≤n)\b.*\b(gi√°|price|r·∫ª|ƒë·∫Øt)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(gi√°|price)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    
                    # General follow-ups
                    (r'\b(c√≤n|c√≥)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.7),
                    (r'\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.7),
                    (r'\b(c√≤n|c√≥)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.6),
                    
                    # Disappointment/confusion follow-ups
                    (r'\b(·ªßa|uhm|hmm|kh√¥ng c√≥|kh√¥ng)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(ph√π h·ª£p|t·ªët|ƒë·∫πp)\b', 0.8),
                    (r'\b(·ªßa|uhm|hmm)\b.*\b(kh√¥ng c√≥|kh√¥ng)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b', 0.7),
                    (r'\b(kh√¥ng c√≥|kh√¥ng)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(ph√π h·ª£p|t·ªët|ƒë·∫πp)\b', 0.7),
                ],
                'promotion': [
                    (r'\b(c√≤n|c√≥)\b.*\b(khuy·∫øn m√£i|sale|discount|m√£|voucher)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(khuy·∫øn m√£i|sale|discount)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                ],
                'order_status': [
                    (r'\b(c√≤n|c√≥)\b.*\b(ƒë∆°n h√†ng|order)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(ƒë∆°n h√†ng|order)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                ]
            }
            
            # Check for follow-up patterns based on last intent
            if last_intent in follow_up_patterns:
                for pattern, confidence in follow_up_patterns[last_intent]:
                    if re.search(pattern, message_lower):
                        return last_intent, confidence
            
            # Context-based intent inheritance for short messages
            if len(message.strip()) < 30:  # Short follow-up messages
                if last_intent == 'product_search' and any(word in message_lower for word in ['c√≤n', 'c√≥', 'kh√°c', 'n√†o', '·ªßa', 'kh√¥ng', 'size', 'gi√°', 'm√†u', 'th∆∞∆°ng hi·ªáu', 'brand', 'ƒë√¥i', 'gi√†y']):
                    return 'product_search', 0.8
                elif last_intent == 'promotion' and any(word in message_lower for word in ['c√≤n', 'c√≥', 'kh√°c', 'n√†o', 'khuy·∫øn m√£i', 'sale']):
                    return 'promotion', 0.8
                elif last_intent == 'order_status' and any(word in message_lower for word in ['c√≤n', 'c√≥', 'kh√°c', 'n√†o', 'ƒë∆°n h√†ng', 'order']):
                    return 'order_status', 0.8
                elif last_intent == 'order_change_request' and any(word in message_lower for word in ['ƒë·ªïi', 'sang', 'm√†u', 'size', 'tr·∫Øng', 'ƒëen', 'xanh', 'ƒë·ªè']):
                    return 'order_change_request', 0.8
        
        # Greeting detection - check first for better accuracy (but not for follow-up questions)
        if not context and (any(word in message_lower for word in ['hey', 'hello', 'hi', 'ch√†o', 'xin ch√†o', 'xin chao']) or len(message.strip()) < 3):
            return 'greeting', 0.9
        
        # S·ª≠ d·ª•ng NLP processor ƒë·ªÉ detect intent
        intent, confidence = self.nlp_processor.fuzzy_match(message, [])
        
        # N·∫øu confidence th·∫•p, th·ª≠ c√°c pattern ƒë∆°n gi·∫£n v√† keyword-based detection
        if confidence < 0.4:  # Lower threshold for better coverage
            # Order status detection
            if any(word in message_lower for word in ['ƒë∆°n h√†ng', 'order', 'c·ªßa t√¥i', 'c·ªßa m√¨nh', 'g·∫ßn ƒë√¢y', 'xem']):
                if any(word in message_lower for word in ['ƒë∆°n h√†ng', 'order']):
                    return 'order_status', 0.7
            
            # Promotion detection
            if any(word in message_lower for word in ['khuy·∫øn m√£i', 'sale', 'discount', 'gi·∫£m gi√°', 'm√£', 'coupon', 'voucher']):
                return 'promotion', 0.7
            
            # Product search detection
            elif any(word in message_lower for word in ['gi√†y', 'd√©p', 'shoe', 'sneaker', 'boot', 'sandal', 'mua', 't√¨m', 'c·∫ßn']):
                return 'product_search', 0.6
            
            # Recommendation detection
            elif any(word in message_lower for word in ['g·ª£i √Ω', 'suggest', 'recommend', 't·ªët', 'ƒë·∫πp', 'hay', 'n√™n']):
                return 'recommendation', 0.6
            
            # Help detection
            elif any(word in message_lower for word in ['gi√∫p', 'help', 'h∆∞·ªõng d·∫´n', 'l√†m sao', 'nh∆∞ th·∫ø n√†o', 'kh√¥ng bi·∫øt']):
                return 'help', 0.6
            
            # Order change request detection
            elif any(word in message_lower for word in ['ƒë·ªïi', 'thay ƒë·ªïi', 'change', 'swap', 'mu·ªën ƒë·ªïi']):
                return 'order_change_request', 0.7
        
        return intent, confidence
    
    def generate_intelligent_response(self, message: str, intent: str, context: List[Dict] = None) -> Dict[str, Any]:
        """T·∫°o ph·∫£n h·ªìi th√¥ng minh b·∫±ng Gemini Flash v·ªõi context t·ª´ database - Optimized for speed"""
        # Ensure model is initialized
        if not self.model:
            self._initialize_gemini_model()
        
        if not self.model:
            return self._get_fallback_response_with_data(intent, context)
        
        try:
            # X√¢y d·ª±ng context t·ª´ database - T·ªëi ∆∞u cho t·ªëc ƒë·ªô
            product_context = self.context_builder.get_products_context(10)  # Gi·∫£m t·ª´ 20 xu·ªëng 10
            promotion_context = self.context_builder.get_promotions_context()
            
            # X√¢y d·ª±ng conversation context - T·ªëi ∆∞u
            conversation_context = ""
            if context and len(context) > 0:
                recent_messages = context[-2:]  # Gi·∫£m t·ª´ 3 xu·ªëng 2 tin nh·∫Øn g·∫ßn nh·∫•t
                for conv in recent_messages:
                    conversation_context += f"Kh√°ch: {conv['message']}\n"
                    conversation_context += f"Footy: {conv['response'][:80]}...\n"  # Gi·∫£m t·ª´ 100 xu·ªëng 80
            
            # T·∫°o prompt ng·∫Øn g·ªçn v√† t·ªëi ∆∞u cho Gemini Flash
            prompt = f"""B·∫°n l√† Footy ‚Äì tr·ª£ l√Ω mua s·∫Øm gi√†y d√©p t·∫°i FootFashion.

S·∫£n ph·∫©m hi·ªán c√≥:
{product_context}

Khuy·∫øn m√£i:
{promotion_context}

H·ªôi tho·∫°i g·∫ßn ƒë√¢y:
{conversation_context}

Kh√°ch h·ªèi: "{message}"

Tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán, d√πng emoji nh·∫π. Gi·ªçng Gen Z nh∆∞ng l·ªãch s·ª±. N·∫øu kh√¥ng c√≥ s·∫£n ph·∫©m ph√π h·ª£p th√¨ g·ª£i √Ω kh√°c.

Tr·∫£ l·ªùi:"""

            # G·ªçi Gemini Flash API v·ªõi timeout ng·∫Øn
            response = self.model.generate_content(prompt)
            
            if response and response.text:
                ai_response = response.text.strip()
            else:
                return self._get_fallback_response_with_data(intent, context)
            
            # L·∫•y th√¥ng tin s·∫£n ph·∫©m v√† promotions ƒë·ªÉ tr·∫£ v·ªÅ c√πng response
            products_data = self._get_relevant_products(message, intent)
            promotions_data = self._get_relevant_promotions(message, intent)
            
            return {
                'content': ai_response,
                'products': products_data,
                'promotions': promotions_data
            }
                
        except Exception as e:
            logger.error(f"Gemini Flash API error: {e}")
            # Check if it's a quota error
            if "quota" in str(e).lower() or "429" in str(e):
                logger.warning("Gemini API quota exceeded, using fallback response")
            return self._get_fallback_response_with_data(intent, context)
    
    def generate_ai_response(self, message: str, intent: str, context: List[Dict] = None, sentiment: Dict = None, confidence: float = 0.0) -> str:
        """Wrapper method ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©"""
        response_data = self.generate_intelligent_response(message, intent, context)
        if isinstance(response_data, dict):
            return response_data.get('content', '')
        return response_data
    
    def _get_relevant_products(self, message: str, intent: str) -> List[Dict]:
        """L·∫•y s·∫£n ph·∫©m li√™n quan d·ª±a tr√™n message v√† intent"""
        try:
            message_lower = message.lower()
            
            # L·∫•y s·∫£n ph·∫©m d·ª±a tr√™n intent
            if intent in ['product_search', 'recommendation']:
                # T√¨m ki·∫øm s·∫£n ph·∫©m d·ª±a tr√™n keywords
                query = Q()
                
                # Brand search
                brands = ['nike', 'adidas', 'puma', 'vans', 'converse']
                for brand in brands:
                    if brand in message_lower:
                        query |= Q(brand__name__icontains=brand)
                
                # Gender search
                if 'nam' in message_lower and 'n·ªØ' not in message_lower:
                    query |= Q(gender__name__icontains='Nam')
                elif 'n·ªØ' in message_lower or 'nu' in message_lower:
                    query |= Q(gender__name__icontains='N·ªØ')
                
                # Category search
                categories = ['sneaker', 'boot', 'sandal', 'gi√†y', 'd√©p']
                for category in categories:
                    if category in message_lower:
                        query |= Q(category__name__icontains=category)
                
                # Price search
                if 'r·∫ª' in message_lower or 'cheap' in message_lower:
                    query |= Q(price__lt=1000000)  # D∆∞·ªõi 1 tri·ªáu
                elif 'ƒë·∫Øt' in message_lower or 'expensive' in message_lower:
                    query |= Q(price__gt=2000000)  # Tr√™n 2 tri·ªáu
                
                # N·∫øu c√≥ query th√¨ t√¨m ki·∫øm, kh√¥ng th√¨ l·∫•y top products
                if query:
                    products = Product.objects.select_related('brand', 'category', 'gender').prefetch_related(
                        'sizes', 'colors', 'images'
                    ).filter(query).order_by('-sales_count', '-id')[:3]
                else:
                    products = Product.objects.select_related('brand', 'category', 'gender').prefetch_related(
                        'sizes', 'colors', 'images'
                    ).order_by('-sales_count', '-id')[:3]
                
                # Convert to frontend format
                products_data = []
                for product in products:
                    # L·∫•y h√¨nh ·∫£nh ƒë·∫ßu ti√™n
                    first_image = product.images.first()
                    image_url = None
                    if first_image and first_image.image:
                        from django.conf import settings
                        image_url = f"{settings.BACKEND_ORIGIN}{first_image.image.url}"
                    
                    products_data.append({
                        'id': product.id,
                        'name': product.name,
                        'brand': product.brand.name if product.brand else 'Unknown',
                        'price': float(product.price),
                        'image': image_url,
                        'link': f"/product/{product.id}"
                    })
                
                return products_data
            
            return []
            
        except Exception as e:
            logger.error(f"Error getting relevant products: {e}")
            return []
    
    def _get_relevant_promotions(self, message: str, intent: str) -> List[Dict]:
        """L·∫•y promotions li√™n quan d·ª±a tr√™n message v√† intent"""
        try:
            if intent == 'promotion' or 'khuy·∫øn m√£i' in message.lower() or 'sale' in message.lower():
                now = timezone.now()
                promotions = Promotion.objects.filter(
                    is_active=True,
                    start_date__lte=now,
                    end_date__gte=now
                ).order_by('-discount_percentage')[:2]
                
                promotions_data = []
                for promo in promotions:
                    promotions_data.append({
                        'code': promo.code,
                        'discount_percentage': promo.discount_percentage,
                        'description': promo.description or f"Gi·∫£m {promo.discount_percentage}%",
                        'end_date': promo.end_date.isoformat() if promo.end_date else None
                    })
                
                return promotions_data
            
            return []
            
        except Exception as e:
            logger.error(f"Error getting relevant promotions: {e}")
            return []
    
    def _get_fallback_response_with_data(self, intent: str, context: List[Dict] = None) -> Dict[str, Any]:
        """Ph·∫£n h·ªìi d·ª± ph√≤ng v·ªõi data khi Gemini API l·ªói"""
        responses = {
            'greeting': "Xin ch√†o! T√¥i l√† Footy, tr·ª£ l√Ω mua s·∫Øm c·ªßa FootFashion! üëã\n\nT√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\nüîç T√¨m ki·∫øm gi√†y d√©p\nüí° G·ª£i √Ω s·∫£n ph·∫©m\nüéâ Xem khuy·∫øn m√£i\nüì¶ Ki·ªÉm tra ƒë∆°n h√†ng\n\nB·∫°n c·∫ßn g√¨ nh√©?",
            'product_search': "Ok n√®! üëã Footy ƒë√¢y, tr·ª£ l√Ω b√°n h√†ng c·ªßa FootFashion! B·∫°n mu·ªën t√¨m ƒë√¥i gi√†y n√†o ph√π h·ª£p kh√¥ng? üòä",
            'recommendation': "Chu·∫©n lu√¥n, ƒë·ªÉ em g·ª£i √Ω li·ªÅn nha üëü Em s·∫Ω t√¨m nh·ªØng ƒë√¥i gi√†y ph√π h·ª£p nh·∫•t cho b·∫°n!",
            'promotion': "Em s·∫Ω ki·ªÉm tra khuy·∫øn m√£i hi·ªán t·∫°i cho b·∫°n nha! üéâ",
            'order_status': "Em s·∫Ω ki·ªÉm tra tr·∫°ng th√°i ƒë∆°n h√†ng c·ªßa b·∫°n nha! üì¶",
            'order_change_request': "Em s·∫Ω gi√∫p b·∫°n thay ƒë·ªïi ƒë∆°n h√†ng! B·∫°n mu·ªën ƒë·ªïi size, m√†u s·∫Øc hay g√¨ kh√°c? üîÑ",
            'help': "Ok n√®! Em ·ªü ƒë√¢y ƒë·ªÉ gi√∫p b·∫°n nha üÜò B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√†y d√©p, khuy·∫øn m√£i, ho·∫∑c ƒë∆°n h√†ng!",
            'unknown': "Ui em ch∆∞a hi·ªÉu r√µ √Ω b·∫°n l·∫Øm üòÖ B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√†y d√©p, khuy·∫øn m√£i, ho·∫∑c ƒë∆°n h√†ng nha! Em s·∫Ω c·ªë g·∫Øng hi·ªÉu h∆°n! üòä"
        }
        
        content = responses.get(intent, responses['unknown'])
        
        # L·∫•y th√¥ng tin s·∫£n ph·∫©m v√† promotions cho fallback
        products_data = self._get_relevant_products("", intent)
        promotions_data = self._get_relevant_promotions("", intent)
        
        return {
            'content': content,
            'products': products_data,
            'promotions': promotions_data
        }
    
    def _get_fallback_response(self, intent: str, context: List[Dict] = None) -> str:
        """Ph·∫£n h·ªìi d·ª± ph√≤ng khi Gemini API l·ªói"""
        responses = {
            'greeting': "Xin ch√†o! T√¥i l√† Footy, tr·ª£ l√Ω mua s·∫Øm c·ªßa FootFashion! üëã\n\nT√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\nüîç T√¨m ki·∫øm gi√†y d√©p\nüí° G·ª£i √Ω s·∫£n ph·∫©m\nüéâ Xem khuy·∫øn m√£i\nüì¶ Ki·ªÉm tra ƒë∆°n h√†ng\n\nB·∫°n c·∫ßn g√¨ nh√©?",
            'product_search': "Ok n√®! üëã Footy ƒë√¢y, tr·ª£ l√Ω b√°n h√†ng c·ªßa FootFashion! B·∫°n mu·ªën t√¨m ƒë√¥i gi√†y n√†o ph√π h·ª£p kh√¥ng? üòä",
            'recommendation': "Chu·∫©n lu√¥n, ƒë·ªÉ em g·ª£i √Ω li·ªÅn nha üëü Em s·∫Ω t√¨m nh·ªØng ƒë√¥i gi√†y ph√π h·ª£p nh·∫•t cho b·∫°n!",
            'promotion': "Em s·∫Ω ki·ªÉm tra khuy·∫øn m√£i hi·ªán t·∫°i cho b·∫°n nha! üéâ",
            'order_status': "Em s·∫Ω ki·ªÉm tra tr·∫°ng th√°i ƒë∆°n h√†ng c·ªßa b·∫°n nha! üì¶",
            'order_change_request': "Em s·∫Ω gi√∫p b·∫°n thay ƒë·ªïi ƒë∆°n h√†ng! B·∫°n mu·ªën ƒë·ªïi size, m√†u s·∫Øc hay g√¨ kh√°c? üîÑ",
            'help': "Ok n√®! Em ·ªü ƒë√¢y ƒë·ªÉ gi√∫p b·∫°n nha üÜò B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√†y d√©p, khuy·∫øn m√£i, ho·∫∑c ƒë∆°n h√†ng!",
            'unknown': "Ui em ch∆∞a hi·ªÉu r√µ √Ω b·∫°n l·∫Øm üòÖ B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√†y d√©p, khuy·∫øn m√£i, ho·∫∑c ƒë∆°n h√†ng nha! Em s·∫Ω c·ªë g·∫Øng hi·ªÉu h∆°n! üòä"
        }
        return responses.get(intent, responses['unknown'])
    
    def get_cached_response(self, message: str, intent: str) -> Optional[str]:
        """L·∫•y ph·∫£n h·ªìi t·ª´ cache - Optimized for speed"""
        # T·∫°o cache key ƒë∆°n gi·∫£n h∆°n ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        cache_key = f"footy_{hash(message.lower().strip())}_{intent}"
        return cache.get(cache_key)
    
    def cache_response(self, message: str, intent: str, response: str):
        """L∆∞u ph·∫£n h·ªìi v√†o cache - Optimized for speed"""
        # T·∫°o cache key ƒë∆°n gi·∫£n h∆°n v√† tƒÉng th·ªùi gian cache
        cache_key = f"footy_{hash(message.lower().strip())}_{intent}"
        cache.set(cache_key, response, 7200)  # Cache 2 gi·ªù thay v√¨ 1 gi·ªù
    
    
    def process_message(self, message: str, user_id: str = None, session_id: str = None) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω tin nh·∫Øn ch√≠nh c·ªßa chatbot - Optimized for speed
        """
        start_time = time.time()
        
        # Validate input
        if not message or not message.strip():
            return {
                "type": "message",
                "content": "Xin l·ªói, t√¥i kh√¥ng hi·ªÉu. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√†y d√©p, khuy·∫øn m√£i, ho·∫∑c ƒë∆°n h√†ng nh√©! üòä",
                "intent": "unknown",
                "confidence": 0.0,
                "sentiment": {"sentiment": "neutral", "confidence": 0.0},
                "processing_time": 0.0,
                "timestamp": timezone.now().isoformat()
            }
        
        # L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i - T·ªëi ∆∞u
        context = self.memory.get_context(user_id or session_id) if (user_id or session_id) else []
        
        # Ph√¢n t√≠ch c·∫£m x√∫c - T·ªëi ∆∞u
        sentiment = self.sentiment_analyzer.analyze_sentiment(message)
        
        # Nh·∫≠n di·ªán √Ω ƒë·ªãnh v·ªõi confidence score - T·ªëi ∆∞u
        intent, confidence = self.detect_intent(message, context)
        
        # Ki·ªÉm tra cache tr∆∞·ªõc - ∆Øu ti√™n cache ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        cached_response = self.get_cached_response(message, intent)
        if cached_response:
            # Cache ch·ªâ l∆∞u content, c·∫ßn l·∫•y th√™m products v√† promotions
            ai_response_data = {
                'content': cached_response,
                'products': self._get_relevant_products(message, intent),
                'promotions': self._get_relevant_promotions(message, intent)
            }
            logger.info(f"‚úÖ Using cached response for intent: {intent}")
        else:
            # T·∫°o ph·∫£n h·ªìi AI v·ªõi confidence - Ch·ªâ khi kh√¥ng c√≥ cache
            ai_response_data = self.generate_intelligent_response(message, intent, context)
            # L∆∞u v√†o cache ch·ªâ content
            self.cache_response(message, intent, ai_response_data.get('content', ''))
            logger.info(f"üîÑ Generated new response for intent: {intent}")
        
        # T√≠nh th·ªùi gian x·ª≠ l√Ω
        processing_time = (time.time() - start_time) * 1000  # ms
        
        # Chu·∫©n b·ªã response data
        response_data = {
            "type": "message",
            "content": ai_response_data.get('content', ''),
            "products": ai_response_data.get('products', []),
            "promotions": ai_response_data.get('promotions', []),
            "intent": intent,
            "confidence": confidence,
            "sentiment": sentiment,
            "processing_time": processing_time,
            "timestamp": timezone.now().isoformat()
        }
        
        # L∆∞u v√†o memory - Ch·ªâ khi c·∫ßn thi·∫øt
        if user_id or session_id:
            self.memory.add_conversation(user_id or session_id, message, ai_response_data.get('content', ''), intent)
        
        return response_data


# Global instance
footy_ai = FootyAI()
