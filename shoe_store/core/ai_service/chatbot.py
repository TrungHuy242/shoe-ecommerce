"""
Footy AI Assistant v2.0 - Intelligent Shopping Assistant for FootFashion
N√¢ng c·∫•p v·ªõi Gemini Pro v√† context-aware product recommendations
"""

import os
import re
import time
from typing import Dict, List, Any, Optional, Tuple
from collections import deque
import google.generativeai as genai
from django.conf import settings
from django.db.models import Q
from django.utils import timezone
from django.core.cache import cache
from difflib import SequenceMatcher
import logging

# Import Django models
from ..models import Product, Brand, Category, Gender, Size, Color, Promotion, Order

logger = logging.getLogger(__name__)

# Configure Gemini API
GEMINI_API_KEY = getattr(settings, 'GEMINI_API_KEY', None) or os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)


class ConversationMemory:
    """Qu·∫£n l√Ω ng·ªØ c·∫£nh h·ªôi tho·∫°i n√¢ng cao v·ªõi User Preferences Tracking"""
    
    def __init__(self, max_size: int = 5):
        self.memories = {}  # user_id -> deque of conversations
        self.max_size = max_size
        self.pending_questions = {}  # user_id -> dict v·ªõi th√¥ng tin c√¢u h·ªèi ƒëang ch·ªù
        self.user_preferences = {}  # user_id -> dict c·ªßa preferences (brand, gender, price_range, etc.)
    
    def add_conversation(self, user_id: str, message: str, response: str, intent: str):
        """Th√™m cu·ªôc h·ªôi tho·∫°i v√†o memory"""
        if user_id not in self.memories:
            self.memories[user_id] = deque(maxlen=self.max_size)
        
        conversation = {
            'message': message,
            'response': response,
            'intent': intent,
            'timestamp': timezone.now().isoformat()
        }
        self.memories[user_id].append(conversation)
    
    def get_context(self, user_id: str) -> List[Dict]:
        """L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i g·∫ßn nh·∫•t"""
        return list(self.memories.get(user_id, []))
    
    def clear_context(self, user_id: str):
        """X√≥a ng·ªØ c·∫£nh c·ªßa user"""
        if user_id in self.memories:
            del self.memories[user_id]
        if user_id in self.pending_questions:
            del self.pending_questions[user_id]
    
    def set_pending_question(self, user_id: str, question_type: str, context: Dict):
        """L∆∞u pending question cho multi-turn conversation"""
        self.pending_questions[user_id] = {
            'question_type': question_type,
            'context': context,
            'timestamp': timezone.now().isoformat()
        }
    
    def get_pending_question(self, user_id: str) -> Optional[Dict]:
        """L·∫•y pending question n·∫øu c√≥"""
        return self.pending_questions.get(user_id)
    
    def clear_pending_question(self, user_id: str):
        """X√≥a pending question sau khi ƒë√£ c√≥ ƒë·ªß th√¥ng tin"""
        if user_id in self.pending_questions:
            del self.pending_questions[user_id]
    
    def update_user_preferences(self, user_id: str, entities: Dict):
        """C·∫≠p nh·∫≠t preferences c·ªßa user d·ª±a tr√™n entities ƒë∆∞·ª£c tr√≠ch xu·∫•t"""
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = {
                'favorite_brands': [],
                'favorite_gender': None,
                'price_range': {'min': None, 'max': None},
                'favorite_colors': [],
                'favorite_categories': [],
                'search_count': 0,
                'last_updated': timezone.now().isoformat()
            }
        
        prefs = self.user_preferences[user_id]
        prefs['search_count'] += 1
        prefs['last_updated'] = timezone.now().isoformat()
        
        # Update favorite brands
        if 'brand' in entities and entities['brand'] not in prefs['favorite_brands']:
            prefs['favorite_brands'].append(entities['brand'])
            if len(prefs['favorite_brands']) > 5:  # Keep top 5
                prefs['favorite_brands'] = prefs['favorite_brands'][-5:]
        
        # Update favorite gender (most recent)
        if 'gender' in entities:
            prefs['favorite_gender'] = entities['gender']
        
        # Update price range
        if 'max_price' in entities:
            if prefs['price_range']['max'] is None or entities['max_price'] > prefs['price_range']['max']:
                prefs['price_range']['max'] = entities['max_price']
        if 'min_price' in entities:
            if prefs['price_range']['min'] is None or entities['min_price'] < prefs['price_range']['min']:
                prefs['price_range']['min'] = entities['min_price']
        
        # Update favorite colors
        if 'color' in entities and entities['color'] not in prefs['favorite_colors']:
            prefs['favorite_colors'].append(entities['color'])
            if len(prefs['favorite_colors']) > 3:  # Keep top 3
                prefs['favorite_colors'] = prefs['favorite_colors'][-3:]
        
        # Update favorite categories
        if 'category' in entities and entities['category'] not in prefs['favorite_categories']:
            prefs['favorite_categories'].append(entities['category'])
            if len(prefs['favorite_categories']) > 3:  # Keep top 3
                prefs['favorite_categories'] = prefs['favorite_categories'][-3:]
    
    def get_user_preferences(self, user_id: str) -> Dict:
        """L·∫•y preferences c·ªßa user"""
        return self.user_preferences.get(user_id, {})


class ProductContextBuilder:
    """X√¢y d·ª±ng context s·∫£n ph·∫©m t·ª´ database"""
    
    @staticmethod
    def get_products_context(limit: int = 15) -> str:
        """L·∫•y context s·∫£n ph·∫©m t·ª´ database - Optimized for speed"""
        try:
            # L·∫•y s·∫£n ph·∫©m v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß - Gi·∫£m limit ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
            products = Product.objects.select_related('brand', 'category', 'gender').prefetch_related(
                'sizes', 'colors', 'images'
            ).order_by('-sales_count', '-id')[:limit]  # ∆Øu ti√™n s·∫£n ph·∫©m b√°n ch·∫°y
            
            if not products.exists():
                return "Hi·ªán t·∫°i c·ª≠a h√†ng ch∆∞a c√≥ s·∫£n ph·∫©m n√†o."
            
            context_lines = []
            for product in products:
                # T·∫°o m√¥ t·∫£ ng·∫Øn g·ªçn cho t·ª´ng s·∫£n ph·∫©m - T·ªëi ∆∞u cho t·ªëc ƒë·ªô
                description_parts = []
                
                # T√™n v√† th∆∞∆°ng hi·ªáu
                description_parts.append(f"{product.name} - {product.brand.name}")
                
                # Gi√°
                price_formatted = f"{product.price:,.0f} VND"
                description_parts.append(f"Gi√°: {price_formatted}")
                
                # M√¥ t·∫£ ng·∫Øn - Gi·∫£m ƒë·ªô d√†i ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
                if product.description:
                    short_desc = product.description[:80].strip()  # Gi·∫£m t·ª´ 100 xu·ªëng 80
                    if len(product.description) > 80:
                        short_desc += "..."
                    description_parts.append(f"M√¥ t·∫£: {short_desc}")
                
                # Gi·ªõi t√≠nh
                if product.gender:
                    description_parts.append(f"Gi·ªõi t√≠nh: {product.gender.name}")
                
                # Sizes c√≥ s·∫µn - Gi·∫£m s·ªë l∆∞·ª£ng
                sizes = product.sizes.all()[:3]  # Gi·∫£m t·ª´ 5 xu·ªëng 3
                if sizes:
                    size_values = [str(size.value) for size in sizes]
                    description_parts.append(f"Sizes: {', '.join(size_values)}")
                
                # M√†u s·∫Øc c√≥ s·∫µn - Gi·∫£m s·ªë l∆∞·ª£ng
                colors = product.colors.all()[:2]  # Gi·∫£m t·ª´ 3 xu·ªëng 2
                if colors:
                    color_values = [color.value for color in colors]
                    description_parts.append(f"M√†u s·∫Øc: {', '.join(color_values)}")
                
                # S·ªë l∆∞·ª£ng b√°n ƒë∆∞·ª£c
                if product.sales_count > 0:
                    description_parts.append(f"ƒê√£ b√°n: {product.sales_count} ƒë√¥i")
                
                # Gh√©p th√†nh m·ªôt d√≤ng
                product_line = " | ".join(description_parts)
                context_lines.append(f"- {product_line}")
            
            return "\n".join(context_lines)
            
        except Exception as e:
            logger.error(f"Error building product context: {e}")
            return "Kh√¥ng th·ªÉ t·∫£i th√¥ng tin s·∫£n ph·∫©m."
    
    @staticmethod
    def get_promotions_context() -> str:
        """L·∫•y context khuy·∫øn m√£i - Optimized for speed"""
        try:
            now = timezone.now()
            promotions = Promotion.objects.filter(
                is_active=True,
                start_date__lte=now,
                end_date__gte=now
            ).order_by('-discount_percentage')[:5]  # Gi·∫£m t·ª´ 10 xu·ªëng 5
            
            if not promotions.exists():
                return "Hi·ªán t·∫°i kh√¥ng c√≥ khuy·∫øn m√£i n√†o."
            
            context_lines = []
            for promo in promotions:
                end_date_str = promo.end_date.strftime('%d/%m/%Y') if promo.end_date else "Kh√¥ng gi·ªõi h·∫°n"
                context_lines.append(
                    f"- M√£: {promo.code} | Gi·∫£m {promo.discount_percentage}% | H·∫øt h·∫°n: {end_date_str}"
                )
            
            return "\n".join(context_lines)
            
        except Exception as e:
            logger.error(f"Error building promotions context: {e}")
            return "Kh√¥ng th·ªÉ t·∫£i th√¥ng tin khuy·∫øn m√£i."


class AdvancedNLPProcessor:
    """X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n n√¢ng cao v·ªõi Fuzzy Matching"""
    
    def __init__(self):
        # T·ª´ ƒë·ªìng nghƒ©a v√† bi·∫øn th·ªÉ - Enhanced for natural language
        self.synonyms = {
            'gi√†y': ['giay', 'gi√†y d√©p', 'shoe', 'shoes', 'sneaker', 'boot', 'ƒë√¥i gi√†y', 'c√°i gi√†y'],
            'd√©p': ['dep', 'sandals', 'flip-flop', 'slipper', 'ƒë√¥i d√©p', 'c√°i d√©p'],
            'nike': ['nike', 'nike air', 'air max', 'jordan'],
            'adidas': ['adidas', 'adidas originals', 'ultraboost'],
            'puma': ['puma', 'puma suede'],
            'vans': ['vans', 'vans old skool'],
            'converse': ['converse', 'chuck taylor', 'all star'],
            'nam': ['nam', 'male', 'men', 'ƒë√†n √¥ng', 'con trai'],
            'n·ªØ': ['n·ªØ', 'nu', 'female', 'women', 'ph·ª• n·ªØ', 'con g√°i'],
            'gi√°': ['gia', 'price', 'cost', 'ti·ªÅn', 'gi√° c·∫£'],
            'r·∫ª': ['re', 'cheap', 'affordable', 'gi√° r·∫ª', 'h·ª£p l√Ω'],
            'ƒë·∫Øt': ['dat', 'expensive', 'gi√° cao', 'm·∫Øc'],
            'size': ['s·ªë', 'k√≠ch c·ª°', 'size', 'c·ª°', 's·ªë gi√†y'],
            'm√†u': ['mau', 'color', 'colour', 'm√†u s·∫Øc'],
            'ƒëen': ['den', 'black'],
            'tr·∫Øng': ['trang', 'white'],
            'ƒë·ªè': ['do', 'red'],
            'xanh': ['blue', 'green'],
            't√¨m': ['tim', 'find', 'search', 'look for', 't√¨m ki·∫øm'],
            'mua': ['buy', 'purchase', 'order', 'mua s·∫Øm'],
            'xem': ['see', 'view', 'look at', 'nh√¨n', 'coi'],
            'g·ª£i √Ω': ['goi y', 'suggest', 'recommend', 'advise', 'ƒë·ªÅ xu·∫•t'],
            'khuy·∫øn m√£i': ['khuyen mai', 'promotion', 'sale', 'discount', '∆∞u ƒë√£i'],
            'gi·∫£m gi√°': ['giam gia', 'discount', 'off', 'sale', 'gi·∫£m'],
            'ƒë∆°n h√†ng': ['don hang', 'order', 'orders', 'ƒë∆°n'],
            'c·ªßa t√¥i': ['cua toi', 'my', 'mine', 'c·ªßa m√¨nh'],
            'g·∫ßn ƒë√¢y': ['gan day', 'recent', 'lately', 'm·ªõi ƒë√¢y'],
            't·ªët': ['tot', 'good', 'nice', 'great', 'ƒë·∫πp', 'hay'],
            'ƒë·∫πp': ['dep', 'beautiful', 'pretty', 'nice', 't·ªët'],
            'hay': ['good', 'great', 'awesome', 't·ªët', 'ƒë·∫πp'],
            'c·∫ßn': ['need', 'want', 'require', 'mu·ªën'],
            'mu·ªën': ['want', 'need', 'desire', 'c·∫ßn'],
            'cho t√¥i': ['cho toi', 'give me', 'show me', 't√¥i mu·ªën'],
            'v√†i': ['some', 'a few', 'm·ªôt v√†i', 'm·ªôt s·ªë'],
            'm·ªôt s·ªë': ['some', 'several', 'v√†i', 'm·ªôt v√†i'],
            'h√¥m nay': ['hom nay', 'today', 'hi·ªán t·∫°i', 'b√¢y gi·ªù']
        }
        
        # Spell correction dictionary (common typos)
        self.spell_corrections = {
            'giay': 'gi√†y',
            'dep': 'd√©p',
            'mau': 'm√†u',
            'gia': 'gi√°',
            're': 'r·∫ª',
            'dat': 'ƒë·∫Øt',
            'tim': 't√¨m',
            'den': 'ƒëen',
            'trang': 'tr·∫Øng',
            'do': 'ƒë·ªè',
            'tot': 't·ªët',
            'nhe': 'nh·∫π',
            'em': '√™m',
            'co': 'c√≥',
            'ko': 'kh√¥ng',
            'k': 'kh√¥ng'
        }
        
        # T·ª´ kh√≥a c·∫£m x√∫c ti·∫øng Vi·ªát - Enhanced for Gen Z
        self.positive_words = [
            't·ªët', 'ƒë·∫πp', 'hay', 'tuy·ªát', 'ok', 'ƒë∆∞·ª£c', 'th√≠ch', 'y√™u', 'h√†i l√≤ng',
            'vui', 'h·∫°nh ph√∫c', 'th√∫ v·ªã', 'th√≠ch th√∫', 'c·∫£m ∆°n', 'thanks', 'perfect',
            'awesome', 'great', 'excellent', 'amazing', 'wonderful',
            'hot', 'hit', 'ngon', 'ch·∫•t', 'x·ªãn', 'ƒë·ªânh', 'pro', 'cool', 'nice',
            '·ªïn', 'ok', 'ƒë∆∞·ª£c', 'tuy·ªát v·ªùi', 'xu·∫•t s·∫Øc', 'tuy·ªát h·∫£o'
        ]
        self.negative_words = [
            't·ªá', 'x·∫•u', 'd·ªü', 'kh√¥ng th√≠ch', 'gh√©t', 'b·ª±c', 't·ª©c', 'kh√≥ ch·ªãu',
            'kh√¥ng h√†i l√≤ng', 'th·∫•t v·ªçng', 'bu·ªìn', 'lo l·∫Øng', 'kh√¥ng ok', 'bad',
            'terrible', 'awful', 'horrible', 'disappointed', 'angry',
            'ƒë·∫Øt', 'm·∫Øc', 'gi√° cao', 's·ª£ mau d∆°', 'kh√¥ng b·ªÅn', 'kh√¥ng √™m',
            'kh√≥ ch·ªãu', 'kh√¥ng ph√π h·ª£p', 'kh√¥ng v·ª´a', 'ch·∫≠t', 'r·ªông',
            'kh√¥ng c√≥', 'h·∫øt h√†ng', 'out of stock', 'sold out'
        ]
        self.urgent_words = [
            'g·∫•p', 'kh·∫©n c·∫•p', 'nhanh', 'ngay', 'l·∫≠p t·ª©c', 'urgent', 'asap',
            'immediately', 'quickly', 'fast', 'hurry'
        ]
        
        # Intent patterns v·ªõi confidence scores - Improved for natural language
        self.intent_patterns = {
            'greeting': [
                (r'\b(xin ch√†o|ch√†o|hello|hi|hey|xin ch[a√†]o)\b', 0.9),
                (r'\b(c√≥ ai|ai ƒë√≥|c√≥ ng∆∞·ªùi)\b', 0.8),
                (r'\b(start|b·∫Øt ƒë·∫ßu|begin)\b', 0.7),
                (r'\b(morning|afternoon|evening)\b', 0.6)
            ],
            'product_search': [
                # Natural language patterns
                (r'\b(t√¥i mu·ªën|t√¥i c·∫ßn|cho t√¥i|t√¨m|mua|xem|c√≥)\b.*\b(gi√†y|d√©p|sneaker|boot|sandal)\b', 0.9),
                (r'\b(gi√†y|d√©p|sneaker|boot|sandal)\b.*\b(nike|adidas|puma|vans|converse)\b', 0.9),
                (r'\b(nike|adidas|puma|vans|converse)\b', 0.8),
                (r'\b(nam|n·ªØ|unisex)\b.*\b(gi√†y|d√©p)\b', 0.8),
                (r'\b(size|m√†u|color|gi√°|price|r·∫ª|ƒë·∫Øt)\b', 0.7),
                (r'\b(d∆∞·ªõi|tr√™n|kho·∫£ng)\b.*\b(tri·ªáu|tr|k|vnd)\b', 0.8),
                (r'\b(gi√†y n√†o|d√©p n√†o|c√≥.*gi√†y|c√≥.*d√©p)\b', 0.7),
                (r'\b(ch·∫°y b·ªô|th·ªÉ thao|c√¥ng s·ªü|ƒëi l√†m|ƒëi ch∆°i|ƒëi h·ªçc)\b', 0.6),
                (r'\b(m·ªôt ƒë√¥i|v√†i ƒë√¥i|v√†i c√°i)\b.*\b(gi√†y|d√©p)\b', 0.6),
                (r'\b(√™m ch√¢n|nh·∫π ch√¢n|tho·∫£i m√°i|comfortable)\b', 0.6),
                (r'\b(ƒë·∫πp|t·ªët|hay|nice|good)\b.*\b(gi√†y|d√©p)\b', 0.6)
            ],
            'recommendation': [
                (r'\b(g·ª£i √Ω|ƒë·ªÅ xu·∫•t|recommend|suggest|n√™n mua|b√°n ch·∫°y|hot|trending)\b', 0.9),
                (r'\b(gi√†y n√†o|d√©p n√†o|s·∫£n ph·∫©m n√†o)\b.*\b(t·ªët|ƒë·∫πp|ch·∫•t l∆∞·ª£ng|b·ªÅn|hay)\b', 0.8),
                (r'\b(top|best|t·ªët nh·∫•t|hay nh·∫•t|ƒë·∫πp nh·∫•t)\b', 0.8),
                (r'\b(ph√π h·ª£p|h·ª£p v·ªõi)\b', 0.7),
                (r'\b(popular|trending|favorite)\b', 0.7),
                (r'\b(g·ª£i √Ω cho|suggest for|recommend for)\b', 0.8),
                (r'\b(c√≥ g·ª£i √Ω|c√≥ suggest|c√≥ recommend)\b', 0.8),
                (r'\b(ƒëi l√†m|ƒëi h·ªçc|c√¥ng s·ªü|th·ªÉ thao)\b.*\b(g·ª£i √Ω|suggest)\b', 0.7)
            ],
            'promotion': [
                (r'\b(khuy·∫øn m√£i|gi·∫£m gi√°|sale|discount|voucher|m√£ gi·∫£m|coupon|∆∞u ƒë√£i)\b', 0.9),
                (r'\b(m√£|code|promo)\b', 0.8),
                (r'\b(gi·∫£m|discount|off)\b', 0.7),
                (r'\b(deal|offer|special)\b', 0.6),
                (r'\b(xem.*khuy·∫øn m√£i|xem.*sale|c√≥.*khuy·∫øn m√£i|c√≥.*sale)\b', 0.8),
                (r'\b(h√¥m nay|today|hi·ªán t·∫°i|now)\b.*\b(khuy·∫øn m√£i|sale|gi·∫£m gi√°)\b', 0.7),
                (r'\b(c√≥.*khuy·∫øn m√£i|c√≥.*sale|c√≥.*gi·∫£m gi√°)\b', 0.8),
                (r'\b(khuy·∫øn m√£i.*h√¥m nay|sale.*h√¥m nay|gi·∫£m gi√°.*h√¥m nay)\b', 0.8)
            ],
            'order_status': [
                (r'\b(ƒë∆°n h√†ng|order|giao h√†ng|v·∫≠n chuy·ªÉn|ship|tracking|theo d√µi)\b', 0.9),
                (r'\b(tr·∫°ng th√°i|t√¨nh tr·∫°ng|status)\b', 0.8),
                (r'\b(khi n√†o|bao gi·ªù|when)\b.*\b(giao|deliver)\b', 0.8),
                (r'\b(tracking|shipment|delivery)\b', 0.7),
                (r'\b(xem.*ƒë∆°n h√†ng|xem.*order|c·ªßa t√¥i|c·ªßa m√¨nh)\b', 0.8),
                (r'\b(g·∫ßn ƒë√¢y|recent|m·ªõi nh·∫•t|latest)\b.*\b(ƒë∆°n h√†ng|order)\b', 0.7)
            ],
            'help': [
                (r'\b(gi√∫p|help|h∆∞·ªõng d·∫´n|h·ªó tr·ª£|support|tr·ª£ gi√∫p)\b', 0.9),
                (r'\b(l√†m sao|how|nh∆∞ th·∫ø n√†o)\b', 0.8),
                (r'\b(help|h·ªó tr·ª£|guide)\b', 0.7),
                (r'\b(tutorial|instruction|manual)\b', 0.6),
                (r'\b(kh√¥ng bi·∫øt|confused|b·ªëi r·ªëi)\b', 0.7)
            ],
            'order_change_request': [
                (r'\b(ƒë·ªïi|thay ƒë·ªïi|change|swap)\b.*\b(size|m√†u|color|ƒë∆°n h√†ng|order)\b', 0.9),
                (r'\b(ƒë·∫∑t|order)\b.*\b(h√¥m qua|yesterday|tr∆∞·ªõc)\b.*\b(ƒë·ªïi|change|thay)\b', 0.9),
                (r'\b(mu·ªën ƒë·ªïi|want to change|thay ƒë·ªïi)\b', 0.8),
                (r'\b(ƒë·ªïi sang|change to|switch to)\b', 0.8),
                (r'\b(size|m√†u|color)\b.*\b(kh√°c|different|other)\b', 0.7)
            ]
        }
    
    def correct_spelling(self, text: str) -> str:
        """S·ª≠a l·ªói ch√≠nh t·∫£ ph·ªï bi·∫øn trong ti·∫øng Vi·ªát"""
        words = text.split()
        corrected_words = []
        
        for word in words:
            # Check if word needs correction
            corrected_word = self.spell_corrections.get(word.lower(), word)
            corrected_words.append(corrected_word)
        
        return ' '.join(corrected_words)
    
    def normalize_text(self, text: str) -> str:
        """Chu·∫©n h√≥a text: lowercase, spell correction, expand synonyms"""
        text = text.lower().strip()
        
        # Spell correction first
        text = self.correct_spelling(text)
        
        # Expand synonyms
        for key, synonyms in self.synonyms.items():
            for synonym in synonyms:
                if synonym in text:
                    text = text.replace(synonym, key)
        
        return text
    
    def fuzzy_match(self, message: str, intents: List[str]) -> Tuple[str, float]:
        """
        Fuzzy matching ƒë·ªÉ nh·∫≠n di·ªán intent v·ªõi ƒë·ªô tin c·∫≠y cao
        S·ª≠ d·ª•ng pattern matching v√† sequence similarity
        Returns: (intent, confidence_score)
        """
        message_normalized = self.normalize_text(message)
        best_intent = 'unknown'
        best_confidence = 0.0
        
        # Try to match against all intent patterns
        for intent, patterns in self.intent_patterns.items():
            for pattern, base_confidence in patterns:
                if re.search(pattern, message_normalized):
                    # Pattern matched, calculate final confidence
                    # Base confidence t·ª´ pattern + boost t·ª´ keyword density
                    keyword_boost = self._calculate_keyword_density(message_normalized, intent)
                    final_confidence = min(base_confidence + keyword_boost, 1.0)
                    
                    if final_confidence > best_confidence:
                        best_confidence = final_confidence
                        best_intent = intent
        
        # If no pattern matched, try keyword-based matching
        if best_confidence < 0.3:
            intent_keywords = self._get_intent_keywords()
            for intent, keywords in intent_keywords.items():
                match_count = sum(1 for keyword in keywords if keyword in message_normalized)
                if match_count > 0:
                    keyword_confidence = min(match_count * 0.2, 0.6)  # Max 0.6 for keyword matching
                    if keyword_confidence > best_confidence:
                        best_confidence = keyword_confidence
                        best_intent = intent
        
        return best_intent, best_confidence
    
    def _calculate_keyword_density(self, text: str, intent: str) -> float:
        """T√≠nh ƒë·ªô m·∫≠t ƒë·ªô keyword cho intent"""
        intent_keywords = {
            'product_search': ['gi√†y', 'd√©p', 't√¨m', 'mua', 'nike', 'adidas', 'puma', 'vans', 'converse'],
            'recommendation': ['g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t', 'recommend', 'suggest', 't·ªët', 'ƒë·∫πp', 'hay'],
            'promotion': ['khuy·∫øn m√£i', 'gi·∫£m gi√°', 'sale', 'discount', 'voucher', 'm√£'],
            'order_status': ['ƒë∆°n h√†ng', 'order', 'giao h√†ng', 'v·∫≠n chuy·ªÉn', 'tracking'],
            'greeting': ['ch√†o', 'hello', 'hi', 'hey'],
            'help': ['gi√∫p', 'help', 'h·ªó tr·ª£', 'h∆∞·ªõng d·∫´n']
        }
        
        keywords = intent_keywords.get(intent, [])
        if not keywords:
            return 0.0
        
        match_count = sum(1 for keyword in keywords if keyword in text)
        return min(match_count * 0.1, 0.3)  # Max boost 0.3
    
    def _get_intent_keywords(self) -> Dict[str, List[str]]:
        """L·∫•y danh s√°ch keywords cho m·ªói intent"""
        return {
            'greeting': ['ch√†o', 'hello', 'hi', 'hey', 'xin ch√†o'],
            'product_search': ['gi√†y', 'd√©p', 't√¨m', 'mua', 'xem', 'nike', 'adidas', 'puma', 'vans', 'converse', 'shoe', 'sneaker'],
            'recommendation': ['g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t', 'recommend', 'suggest', 'n√™n', 't·ªët', 'ƒë·∫πp', 'hay', 'top'],
            'promotion': ['khuy·∫øn m√£i', 'gi·∫£m gi√°', 'sale', 'discount', 'voucher', 'm√£', 'coupon'],
            'order_status': ['ƒë∆°n h√†ng', 'order', 'giao h√†ng', 'v·∫≠n chuy·ªÉn', 'ship', 'tracking'],
            'help': ['gi√∫p', 'help', 'h·ªó tr·ª£', 'h∆∞·ªõng d·∫´n', 'l√†m sao'],
            'order_change_request': ['ƒë·ªïi', 'thay ƒë·ªïi', 'change', 'swap', 'mu·ªën ƒë·ªïi']
        }
    
    def extract_entities(self, text: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t entities t·ª´ text v·ªõi ƒë·ªô ch√≠nh x√°c cao"""
        entities = {}
        normalized_text = self.normalize_text(text)
        original_text = text.lower()
        
        # Extract brand v·ªõi nhi·ªÅu variations
        brands = {
            'nike': ['nike', 'nike air', 'air max', 'jordan', 'air force'],
            'adidas': ['adidas', 'adidas originals', 'ultraboost', 'yeezy', 'stan smith'],
            'puma': ['puma', 'puma suede', 'puma rs'],
            'vans': ['vans', 'vans old skool', 'vans sk8'],
            'converse': ['converse', 'chuck taylor', 'all star', 'converse all star']
        }
        
        for brand_key, brand_variations in brands.items():
            for variation in brand_variations:
                if variation in original_text:
                    entities['brand'] = brand_key.capitalize()
                    break
            if 'brand' in entities:
                break
        
        # Extract gender v·ªõi nhi·ªÅu variations
        if any(word in normalized_text for word in ['nam', 'male', 'men', 'ƒë√†n √¥ng', 'con trai']):
            if 'n·ªØ' not in normalized_text:  # Make sure not "nam n·ªØ"
                entities['gender'] = 'Nam'
        elif any(word in normalized_text for word in ['n·ªØ', 'nu', 'female', 'women', 'ph·ª• n·ªØ', 'con g√°i']):
            entities['gender'] = 'N·ªØ'
        elif 'unisex' in normalized_text or 'nam n·ªØ' in normalized_text:
            entities['gender'] = 'Unisex'
        
        # Extract size v·ªõi nhi·ªÅu formats
        size_patterns = [
            r'size\s*(\d{2})',
            r'(\d{2})\s*size',
            r's·ªë\s*(\d{2})',
            r'(\d{2})\s*s·ªë',
            r'c·ª°\s*(\d{2})',
            r'k√≠ch\s*c·ª°\s*(\d{2})'
        ]
        for pattern in size_patterns:
            match = re.search(pattern, normalized_text)
            if match:
                size_value = match.group(1)
                if 35 <= int(size_value) <= 48:  # Valid shoe size range
                    entities['size'] = size_value
                    break
        
        # Extract color v·ªõi nhi·ªÅu variations
        colors_mapping = {
            'ƒëen': ['ƒëen', 'den', 'black', 'ƒëen nh√°m'],
            'tr·∫Øng': ['tr·∫Øng', 'trang', 'white', 'tr·∫Øng tinh'],
            'ƒë·ªè': ['ƒë·ªè', 'do', 'red', 'ƒë·ªè t∆∞∆°i'],
            'xanh': ['xanh', 'blue', 'navy', 'xanh d∆∞∆°ng', 'xanh l√°'],
            'v√†ng': ['v√†ng', 'vang', 'yellow', 'v√†ng cam'],
            'n√¢u': ['n√¢u', 'nau', 'brown', 'be'],
            'h·ªìng': ['h·ªìng', 'hong', 'pink', 'h·ªìng nh·∫°t'],
            'x√°m': ['x√°m', 'xam', 'gray', 'grey', 'x√°m nh·∫°t'],
            'cam': ['cam', 'orange'],
            't√≠m': ['t√≠m', 'tim', 'purple', 'violet']
        }
        
        for color_key, color_variations in colors_mapping.items():
            for variation in color_variations:
                if variation in normalized_text:
                    entities['color'] = color_key
                    break
            if 'color' in entities:
                break
        
        # Extract price range v·ªõi nhi·ªÅu formats
        price_patterns = [
            (r'd∆∞·ªõi\s*(\d+)\s*(tri·ªáu|tr|k|vnd)', 'max'),
            (r'(\d+)\s*(tri·ªáu|tr|k|vnd)\s*tr·ªü\s*xu·ªëng', 'max'),
            (r'√≠t\s*h∆°n\s*(\d+)\s*(tri·ªáu|tr|k|vnd)', 'max'),
            (r'kh√¥ng\s*qu√°\s*(\d+)\s*(tri·ªáu|tr|k|vnd)', 'max'),
            (r'tr√™n\s*(\d+)\s*(tri·ªáu|tr|k|vnd)', 'min'),
            (r'(\d+)\s*(tri·ªáu|tr|k|vnd)\s*tr·ªü\s*l√™n', 'min'),
            (r't·ª´\s*(\d+)\s*(tri·ªáu|tr|k|vnd)', 'min'),
            (r'kho·∫£ng\s*(\d+)\s*(tri·ªáu|tr|k|vnd)', 'range')
        ]
        
        for pattern, price_type in price_patterns:
            match = re.search(pattern, normalized_text)
            if match:
                amount = int(match.group(1))
                unit = match.group(2)
                
                # Convert to VND
                if 'tri·ªáu' in unit or 'tr' in unit:
                    price_value = amount * 1000000
                elif 'k' in unit:
                    price_value = amount * 1000
                elif 'vnd' in unit:
                    price_value = amount
                else:
                    continue
                
                # Set price entity
                if price_type == 'max':
                    entities['max_price'] = price_value
                elif price_type == 'min':
                    entities['min_price'] = price_value
                elif price_type == 'range':
                    # For "kho·∫£ng X tri·ªáu", set both min and max
                    entities['min_price'] = price_value * 0.8
                    entities['max_price'] = price_value * 1.2
                break
        
        # Extract category/type
        categories = {
            'sneaker': ['sneaker', 'gi√†y th·ªÉ thao', 'gi√†y ch·∫°y b·ªô', 'running'],
            'boot': ['boot', 'gi√†y cao c·ªï', 'gi√†y b·ªët'],
            'sandal': ['sandal', 'd√©p', 'gi√†y sandal', 'd√©p quai'],
            'casual': ['gi√†y casual', 'gi√†y th∆∞·ªùng ng√†y', 'gi√†y ƒëi ch∆°i'],
            'formal': ['gi√†y t√¢y', 'gi√†y c√¥ng s·ªü', 'gi√†y l·ªãch s·ª±']
        }
        
        for category_key, category_variations in categories.items():
            for variation in category_variations:
                if variation in normalized_text:
                    entities['category'] = category_key
                    break
            if 'category' in entities:
                break
        
        # Extract purpose/use case
        purposes = {
            'running': ['ch·∫°y b·ªô', 'running', 't·∫≠p gym', 'th·ªÉ thao'],
            'casual': ['ƒëi ch∆°i', 'd·∫°o ph·ªë', 'casual', 'th∆∞·ªùng ng√†y'],
            'work': ['ƒëi l√†m', 'c√¥ng s·ªü', 'vƒÉn ph√≤ng', 'work'],
            'formal': ['d·ª± ti·ªác', 'formal', 'l·ªãch s·ª±', 'sang tr·ªçng']
        }
        
        for purpose_key, purpose_variations in purposes.items():
            for variation in purpose_variations:
                if variation in normalized_text:
                    entities['purpose'] = purpose_key
                    break
            if 'purpose' in entities:
                break
        
        return entities


class SentimentAnalyzer:
    """Ph√¢n t√≠ch c·∫£m x√∫c ng∆∞·ªùi d√πng n√¢ng cao v·ªõi Negation Handling v√† Intensity Detection"""
    
    def __init__(self):
        # T·ª´ kh√≥a c·∫£m x√∫c ti·∫øng Vi·ªát
        self.positive_words = [
            't·ªët', 'ƒë·∫πp', 'hay', 'tuy·ªát', 'ok', 'ƒë∆∞·ª£c', 'th√≠ch', 'y√™u', 'h√†i l√≤ng',
            'vui', 'h·∫°nh ph√∫c', 'th√∫ v·ªã', 'th√≠ch th√∫', 'c·∫£m ∆°n', 'thanks', 'perfect',
            'awesome', 'great', 'excellent', 'amazing', 'wonderful', 'ch·∫•t', 'x·ªãn', 
            'ƒë·ªânh', 'pro', 'cool', 'nice', '·ªïn', 'xu·∫•t s·∫Øc', 'tuy·ªát v·ªùi'
        ]
        self.negative_words = [
            't·ªá', 'x·∫•u', 'd·ªü', 'kh√¥ng th√≠ch', 'gh√©t', 'b·ª±c', 't·ª©c', 'kh√≥ ch·ªãu',
            'kh√¥ng h√†i l√≤ng', 'th·∫•t v·ªçng', 'bu·ªìn', 'lo l·∫Øng', 'kh√¥ng ok', 'bad',
            'terrible', 'awful', 'horrible', 'disappointed', 'angry', 'k√©m', 't·ªá h·∫°i',
            'kh√¥ng t·ªët', 'kh√¥ng ƒë·∫πp', 'kh√¥ng hay'
        ]
        self.urgent_words = [
            'g·∫•p', 'kh·∫©n c·∫•p', 'nhanh', 'ngay', 'l·∫≠p t·ª©c', 'urgent', 'asap',
            'immediately', 'quickly', 'fast', 'hurry'
        ]
        # T·ª´ ph·ªß ƒë·ªãnh
        self.negation_words = [
            'kh√¥ng', 'ch·∫≥ng', 'ch∆∞a', 'ƒë·ª´ng', 'kh√¥ng ph·∫£i', 'ch·∫£', 'ko', 'k',
            'never', 'not', 'no', 'none'
        ]
        # T·ª´ tƒÉng c∆∞·ªùng (intensifiers)
        self.intensifiers = {
            'r·∫•t': 2.0, 'c·ª±c': 2.5, 'qu√°': 2.0, 'si√™u': 2.5, 'h∆°i': 0.5,
            'kh√°': 1.5, 'very': 2.0, 'too': 2.0, 'extremely': 2.5, 'quite': 1.5,
            'c·ª±c k·ª≥': 2.5, 'v√¥ c√πng': 2.5, 'h∆°i b·ªã': 1.5, 'l·∫Øm': 2.0
        }
    
    def analyze_sentiment(self, message: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ tin nh·∫Øn v·ªõi negation handling v√† intensity"""
        message_lower = message.lower()
        words = message_lower.split()
        
        score = 0
        positive_count = 0
        negative_count = 0
        
        # Advanced sentiment analysis v·ªõi context
        for i, word in enumerate(words):
            # Check negation tr∆∞·ªõc t·ª´ hi·ªán t·∫°i (trong window 3 t·ª´)
            is_negated = False
            intensity_multiplier = 1.0
            
            # Check negation trong 3 t·ª´ tr∆∞·ªõc ƒë√≥
            for j in range(max(0, i-3), i):
                if words[j] in self.negation_words:
                    is_negated = True
                    break
            
            # Check intensifier trong 2 t·ª´ tr∆∞·ªõc ƒë√≥
            for j in range(max(0, i-2), i):
                if words[j] in self.intensifiers:
                    intensity_multiplier = self.intensifiers[words[j]]
                    break
            
            # T√≠nh sentiment score
            if word in self.positive_words:
                if is_negated:
                    score -= 1 * intensity_multiplier
                    negative_count += 1
                else:
                    score += 1 * intensity_multiplier
                    positive_count += 1
            elif word in self.negative_words:
                if is_negated:
                    score += 1 * intensity_multiplier
                    positive_count += 1
                else:
                    score -= 1 * intensity_multiplier
                    negative_count += 1
        
        # X√°c ƒë·ªãnh sentiment
        if score > 0.5:
            sentiment = 'positive'
        elif score < -0.5:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        # Calculate confidence based on score strength
        confidence = min(abs(score) / max(len(words), 1), 1.0)
        
        # X√°c ƒë·ªãnh urgency
        urgent_count = sum(1 for word in self.urgent_words if word in message_lower)
        is_urgent = urgent_count > 0 or message.count('!') >= 2 or '???' in message
        
        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'is_urgent': is_urgent,
            'positive_words': positive_count,
            'negative_words': negative_count,
            'sentiment_score': score  # Raw score for debugging
        }


class FootyAI:
    """AI Shopping Assistant "Footy" cho FootFashion - Advanced Version"""
    
    def __init__(self):
        self.model = None
        self.memory = ConversationMemory()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.nlp_processor = AdvancedNLPProcessor()
        self.context_builder = ProductContextBuilder()
        
        # Initialize Gemini model with proper API key
        self._initialize_gemini_model()
    
    def _initialize_gemini_model(self):
        """Initialize Gemini model with proper API key - Optimized for speed"""
        try:
            # Load API key directly from .env file
            from pathlib import Path
            from dotenv import load_dotenv
            
            # Get project root directory
            project_root = Path(__file__).resolve().parent.parent.parent.parent
            env_path = project_root / '.env'
            
            # Load .env file
            load_dotenv(env_path)
            
            # Get API key
            api_key = os.getenv('GEMINI_API_KEY')
            
            if api_key:
                genai.configure(api_key=api_key)
                # S·ª≠ d·ª•ng Gemini 2.5 Flash - Model nhanh nh·∫•t v√† m·∫°nh nh·∫•t hi·ªán t·∫°i
                self.model = genai.GenerativeModel('gemini-2.5-flash')
                logger.info("Gemini 2.5 Flash model initialized successfully - Optimized for speed")
            else:
                logger.warning("GEMINI_API_KEY not found, Gemini model not initialized")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini 2.5 Flash model: {e}")
            # Fallback to Pro model if Flash is not available
            try:
                if api_key:
                    genai.configure(api_key=api_key)
                    self.model = genai.GenerativeModel('gemini-2.5-pro')
                    logger.info("Fallback to Gemini 2.5 Pro model")
            except Exception as fallback_error:
                logger.error(f"Fallback to Pro model also failed: {fallback_error}")
                # Final fallback to 1.5 Pro
            try:
                if api_key:
                    genai.configure(api_key=api_key)
                    self.model = genai.GenerativeModel('gemini-1.5-pro-latest')
                    logger.info("Fallback to Gemini 1.5 Pro Latest model")
            except Exception as fallback_error:
                logger.error(f"Fallback model also failed: {fallback_error}")
    
    def check_missing_information(self, message: str, intent: str, entities: Dict) -> Optional[Dict]:
        """
        Ki·ªÉm tra th√¥ng tin c√≤n thi·∫øu v√† tr·∫£ v·ªÅ c√¢u h·ªèi c·∫ßn h·ªèi l·∫°i
        QUAN TR·ªåNG: Ch·ªâ h·ªèi l·∫°i 1 l·∫ßn khi th·ª±c s·ª± thi·∫øu th√¥ng tin QUAN TR·ªåNG
        Returns: Dict v·ªõi 'missing': True/False, 'question': str n·∫øu thi·∫øu
        """
        message_lower = message.lower()
        
        # N·∫øu ƒëang ch·ªù tr·∫£ l·ªùi t·ª´ multi-turn conversation
        # Logic n√†y s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω trong process_message
        
        # Ki·ªÉm tra thi·∫øu th√¥ng tin cho product_search
        if intent == 'product_search':
            # KH√îNG h·ªèi l·∫°i n·∫øu c√≥ √≠t nh·∫•t 1 entity (brand ho·∫∑c gender ho·∫∑c price)
            # Ch·ªâ h·ªèi khi ho√†n to√†n kh√¥ng c√≥ th√¥ng tin g√¨
            if not entities or len(entities) == 0:
                # Ho√†n to√†n kh√¥ng c√≥ th√¥ng tin ‚Üí H·ªèi 1 l·∫ßn duy nh·∫•t
                return {
                    'missing': True,
                    'missing_fields': ['any'],
                    'question': "B·∫°n mu·ªën t√¨m gi√†y th∆∞∆°ng hi·ªáu n√†o, hay ƒë·ªÉ em g·ª£i √Ω m·∫•y ƒë√¥i b√°n ch·∫°y nh·∫•t? üòä",
                    'question_type': 'product_search_details'
                }
            
            # C√≥ √≠t nh·∫•t 1 entity ‚Üí KH√îNG h·ªèi l·∫°i, t√¨m lu√¥n
            # V√≠ d·ª•: "t√¨m gi√†y Nike" ‚Üí T√¨m t·∫•t c·∫£ Nike (nam/n·ªØ/unisex)
            # V√≠ d·ª•: "gi√†y nam" ‚Üí T√¨m t·∫•t c·∫£ gi√†y nam c√°c h√£ng
        
        # Ki·ªÉm tra thi·∫øu th√¥ng tin cho order_status
        if intent == 'order_status':
            # N·∫øu user ch∆∞a ƒëƒÉng nh·∫≠p v√† kh√¥ng c√≥ order ID
            if 'order_id' not in entities and 'order' not in message_lower:
                return {
                    'missing': True,
                    'missing_fields': ['order_id'],
                    'question': "B·∫°n cho em m√£ ƒë∆°n h√†ng ƒë·ªÉ ki·ªÉm tra nh√©! Ho·∫∑c ƒëƒÉng nh·∫≠p ƒë·ªÉ em t·ª± check lu√¥n üì¶",
                    'question_type': 'order_status_details'
                }
        
        return {'missing': False}
    
    def detect_intent(self, message: str, context: List[Dict] = None) -> Tuple[str, float]:
        """
        Nh·∫≠n di·ªán √Ω ƒë·ªãnh ng∆∞·ªùi d√πng v·ªõi fuzzy matching v√† confidence score
        Enhanced context awareness for follow-up questions
        Returns: (intent, confidence_score)
        """
        message_lower = message.lower()
        
        # Enhanced context analysis for follow-up questions
        if context and len(context) > 0:
            last_conversation = context[-1]
            last_intent = last_conversation.get('intent', '')
            last_message = last_conversation.get('message', '').lower()
            
            # Follow-up question patterns
            follow_up_patterns = {
                'product_search': [
                    # Brand/type follow-ups
                    (r'\b(c√≤n|c√≥|th√™m)\b.*\b(th∆∞∆°ng hi·ªáu|brand|h√£ng|nike|adidas|puma|vans|converse)\b', 0.9),
                    (r'\b(th∆∞∆°ng hi·ªáu|brand|h√£ng)\b.*\b(kh√°c|kh√°c kh√¥ng|n√†o kh√°c)\b', 0.9),
                    (r'\b(c√≤n|c√≥)\b.*\b(th∆∞∆°ng hi·ªáu|brand|h√£ng)\b.*\b(kh√°c|n√†o)\b', 0.9),
                    
                    # Size/color follow-ups
                    (r'\b(c√≥|c√≤n)\b.*\b(size|m√†u|color|m√†u s·∫Øc)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(size|m√†u|color)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    
                    # Price follow-ups
                    (r'\b(c√≥|c√≤n)\b.*\b(gi√°|price|r·∫ª|ƒë·∫Øt)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(gi√°|price)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    
                    # Image/view follow-ups - IMPORTANT: Show products when asking for images
                    (r'\b(cho|cho t√¥i|cho m√¨nh|cho em)\b.*\b(xem|th·∫•y|nh√¨n|coi)\b.*\b(h√¨nh|·∫£nh|hinh anh|image|photo|picture)\b', 0.95),
                    (r'\b(xem|th·∫•y|nh√¨n|coi)\b.*\b(h√¨nh|·∫£nh|hinh anh|image|photo|picture)\b', 0.9),
                    (r'\b(c√≥|c√≤n)\b.*\b(h√¨nh|·∫£nh|hinh anh|image|photo|picture)\b', 0.85),
                    (r'\b(h√¨nh|·∫£nh|hinh anh|image|photo|picture)\b.*\b(c·ªßa|ƒë√¥i|gi√†y|d√©p|s·∫£n ph·∫©m)\b', 0.9),
                    
                    # Link follow-ups - IMPORTANT: Show products when asking for links
                    (r'\b(cho|cho t√¥i|cho m√¨nh|cho em|g·ª≠i|gui)\b.*\b(link|li√™n k·∫øt|lien ket|ƒë∆∞·ªùng link|duong link|url)\b', 0.95),
                    (r'\b(c√≥|co)\b.*\b(link|li√™n k·∫øt|lien ket|ƒë∆∞·ªùng link|duong link|url)\b', 0.9),
                    (r'\b(link|li√™n k·∫øt|lien ket|ƒë∆∞·ªùng link|duong link|url)\b.*\b(s·∫£n ph·∫©m|san pham|ƒë√¥i|gi√†y|d√©p)\b', 0.9),
                    (r'\b(g·ª≠i|gui|cho)\b.*\b(link|li√™n k·∫øt|lien ket)\b.*\b(xem|m√¨nh|t√¥i)\b', 0.95),
                    
                    # General follow-ups
                    (r'\b(c√≤n|c√≥)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.7),
                    (r'\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.7),
                    (r'\b(c√≤n|c√≥)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.6),
                    
                    # Disappointment/confusion follow-ups
                    (r'\b(·ªßa|uhm|hmm|kh√¥ng c√≥|kh√¥ng)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(ph√π h·ª£p|t·ªët|ƒë·∫πp)\b', 0.8),
                    (r'\b(·ªßa|uhm|hmm)\b.*\b(kh√¥ng c√≥|kh√¥ng)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b', 0.7),
                    (r'\b(kh√¥ng c√≥|kh√¥ng)\b.*\b(ƒë√¥i|gi√†y|d√©p)\b.*\b(ph√π h·ª£p|t·ªët|ƒë·∫πp)\b', 0.7),
                ],
                'promotion': [
                    (r'\b(c√≤n|c√≥)\b.*\b(khuy·∫øn m√£i|sale|discount|m√£|voucher)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(khuy·∫øn m√£i|sale|discount)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                ],
                'order_status': [
                    (r'\b(c√≤n|c√≥)\b.*\b(ƒë∆°n h√†ng|order)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                    (r'\b(ƒë∆°n h√†ng|order)\b.*\b(kh√°c|n√†o|kh√°c kh√¥ng)\b', 0.8),
                ]
            }
            
            # Check for follow-up patterns based on last intent
            if last_intent in follow_up_patterns:
                for pattern, confidence in follow_up_patterns[last_intent]:
                    if re.search(pattern, message_lower):
                        return last_intent, confidence
            
            # Context-based intent inheritance for short messages
            if len(message.strip()) < 30:  # Short follow-up messages
                if last_intent == 'product_search' and any(word in message_lower for word in ['c√≤n', 'c√≥', 'kh√°c', 'n√†o', '·ªßa', 'kh√¥ng', 'size', 'gi√°', 'm√†u', 'th∆∞∆°ng hi·ªáu', 'brand', 'ƒë√¥i', 'gi√†y', 'h√¨nh', '·∫£nh', 'xem', 'cho xem', 'h√¨nh ·∫£nh', 'hinh anh', 'link', 'li√™n k·∫øt', 'lien ket', 'g·ª≠i link', 'gui link']):
                    return 'product_search', 0.8
                elif last_intent == 'promotion' and any(word in message_lower for word in ['c√≤n', 'c√≥', 'kh√°c', 'n√†o', 'khuy·∫øn m√£i', 'sale']):
                    return 'promotion', 0.8
                elif last_intent == 'order_status' and any(word in message_lower for word in ['c√≤n', 'c√≥', 'kh√°c', 'n√†o', 'ƒë∆°n h√†ng', 'order']):
                    return 'order_status', 0.8
                elif last_intent == 'order_change_request' and any(word in message_lower for word in ['ƒë·ªïi', 'sang', 'm√†u', 'size', 'tr·∫Øng', 'ƒëen', 'xanh', 'ƒë·ªè']):
                    return 'order_change_request', 0.8
        
        # Greeting detection - check FIRST before everything else
        greeting_keywords = ['hey', 'hello', 'hi', 'ch√†o', 'xin ch√†o', 'xin chao', 'chao', 'chao ban', 'ch√†o b·∫°n']
        if any(keyword in message_lower for keyword in greeting_keywords) or len(message.strip()) < 3:
            # Only return greeting if not in the middle of a conversation flow
            if not context or len(context) == 0:
                return 'greeting', 0.95
            # If context exists but last intent was greeting, still return greeting
            elif context and len(context) > 0:
                last_intent = context[-1].get('intent', '')
                if last_intent == 'greeting' or any(keyword in message_lower for keyword in greeting_keywords):
                    return 'greeting', 0.9
        
        # S·ª≠ d·ª•ng NLP processor ƒë·ªÉ detect intent
        intent, confidence = self.nlp_processor.fuzzy_match(message, [])
        
        # N·∫øu confidence th·∫•p, th·ª≠ c√°c pattern ƒë∆°n gi·∫£n v√† keyword-based detection
        if confidence < 0.4:  # Lower threshold for better coverage
            # Greeting detection (fallback)
            greeting_keywords = ['hey', 'hello', 'hi', 'ch√†o', 'xin ch√†o', 'xin chao', 'chao', 'chao ban', 'ch√†o b·∫°n']
            if any(keyword in message_lower for keyword in greeting_keywords):
                return 'greeting', 0.8
            
            # Order status detection
            if any(word in message_lower for word in ['ƒë∆°n h√†ng', 'order', 'c·ªßa t√¥i', 'c·ªßa m√¨nh', 'g·∫ßn ƒë√¢y', 'xem']):
                if any(word in message_lower for word in ['ƒë∆°n h√†ng', 'order']):
                    return 'order_status', 0.7
            
            # Promotion detection
            if any(word in message_lower for word in ['khuy·∫øn m√£i', 'sale', 'discount', 'gi·∫£m gi√°', 'm√£', 'coupon', 'voucher']):
                return 'promotion', 0.7
            
            # Product search detection
            elif any(word in message_lower for word in ['gi√†y', 'd√©p', 'shoe', 'sneaker', 'boot', 'sandal', 'mua', 't√¨m', 'c·∫ßn']):
                return 'product_search', 0.6
            
            # Recommendation detection
            elif any(word in message_lower for word in ['g·ª£i √Ω', 'suggest', 'recommend', 't·ªët', 'ƒë·∫πp', 'hay', 'n√™n']):
                return 'recommendation', 0.6
            
            # Help detection
            elif any(word in message_lower for word in ['gi√∫p', 'help', 'h∆∞·ªõng d·∫´n', 'l√†m sao', 'nh∆∞ th·∫ø n√†o', 'kh√¥ng bi·∫øt']):
                return 'help', 0.6
            
            # Order change request detection
            elif any(word in message_lower for word in ['ƒë·ªïi', 'thay ƒë·ªïi', 'change', 'swap', 'mu·ªën ƒë·ªïi']):
                return 'order_change_request', 0.7
        
        return intent, confidence
    
    def generate_intelligent_response(self, message: str, intent: str, context: List[Dict] = None, user_id: str = None, entities: Dict = None) -> Dict[str, Any]:
        """T·∫°o ph·∫£n h·ªìi th√¥ng minh b·∫±ng Gemini Flash v·ªõi context t·ª´ database - Optimized for speed"""
        # Ensure model is initialized
        if not self.model:
            self._initialize_gemini_model()
        
        # Extract entities if not provided
        if not entities:
            entities = self.nlp_processor.extract_entities(message)
        
        # Check for pending questions (multi-turn conversation)
        if user_id:
            pending_question = self.memory.get_pending_question(user_id)
            if pending_question:
                # User ƒëang tr·∫£ l·ªùi c√¢u h·ªèi t·ª´ multi-turn conversation
                question_type = pending_question.get('question_type')
                if question_type == 'product_search_details':
                    # Extract entities t·ª´ c√¢u tr·∫£ l·ªùi
                    new_entities = self.nlp_processor.extract_entities(message)
                    
                    # N·∫øu ƒë√£ c√≥ ƒë·ªß th√¥ng tin, clear pending question v√† ti·∫øp t·ª•c
                    if 'brand' in new_entities or 'gender' in new_entities:
                        self.memory.clear_pending_question(user_id)
                        # Combine v·ªõi context tr∆∞·ªõc ƒë√≥
                        prev_context = pending_question.get('context', {})
                        entities = {**prev_context, **new_entities}
                        # Update message ƒë·ªÉ t√¨m ki·∫øm t·ªët h∆°n
                        message = f"{pending_question.get('context', {}).get('original_message', '')} {message}"
                    else:
                        # V·∫´n thi·∫øu th√¥ng tin, h·ªèi l·∫°i
                        return {
                            'content': "Em v·∫´n ch∆∞a r√µ l·∫Øm üòÖ B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n v·ªÅ th∆∞∆°ng hi·ªáu ho·∫∑c gi·ªõi t√≠nh ƒë∆∞·ª£c kh√¥ng ·∫°? V√≠ d·ª•: 'Nike nam' ho·∫∑c 'Adidas n·ªØ'",
                            'products': [],
                            'promotions': [],
                            'needs_clarification': True
                        }
        
        # ‚úÖ B∆Ø·ªöC 1: T·∫ÆT RULE CLARIFY - ƒê·ªÉ Gemini t·ª± x·ª≠ l√Ω th√¥ng minh
        # Gemini Flash m·∫°nh h∆°n code rule 100 l·∫ßn
        # KH√îNG check missing info n·ªØa, ƒë·ªÉ LLM t·ª± suy lu·∫≠n v√† quy·∫øt ƒë·ªãnh
        
        # DISABLED: check_missing_information()
        # missing_info = self.check_missing_information(message, intent, entities)
        # ‚Üí ƒê·ªÉ Gemini t·ª± x·ª≠ l√Ω d·ª±a v√†o context v√† prompt
        
        if not self.model:
            return self._get_enhanced_fallback_response(intent, context, message, entities)
        
        try:
            # X√¢y d·ª±ng context t·ª´ database - T·ªëi ∆∞u cho t·ªëc ƒë·ªô
            product_context = self.context_builder.get_products_context(10)  # Gi·∫£m t·ª´ 20 xu·ªëng 10
            promotion_context = self.context_builder.get_promotions_context()
            
            # X√¢y d·ª±ng conversation context - T·ªëi ∆∞u
            conversation_context = ""
            if context and len(context) > 0:
                recent_messages = context[-2:]  # Gi·∫£m t·ª´ 3 xu·ªëng 2 tin nh·∫Øn g·∫ßn nh·∫•t
                for conv in recent_messages:
                    conversation_context += f"Kh√°ch: {conv['message']}\n"
                    conversation_context += f"Footy: {conv['response'][:80]}...\n"  # Gi·∫£m t·ª´ 100 xu·ªëng 80
            
            # Get user preferences if available
            user_prefs = self.memory.get_user_preferences(user_id) if user_id else {}
            
            # Build user preferences context
            prefs_context = ""
            if user_prefs and user_prefs.get('search_count', 0) > 0:
                prefs_lines = []
                if user_prefs.get('favorite_brands'):
                    prefs_lines.append(f"- Th∆∞∆°ng hi·ªáu y√™u th√≠ch: {', '.join(user_prefs['favorite_brands'])}")
                if user_prefs.get('favorite_gender'):
                    prefs_lines.append(f"- Gi·ªõi t√≠nh: {user_prefs['favorite_gender']}")
                if user_prefs.get('favorite_colors'):
                    prefs_lines.append(f"- M√†u s·∫Øc y√™u th√≠ch: {', '.join(user_prefs['favorite_colors'])}")
                if prefs_lines:
                    prefs_context = "\n\nS·ªü th√≠ch kh√°ch h√†ng (t·ª´ l·ªãch s·ª≠):\n" + "\n".join(prefs_lines)
            
            # Build entities context
            entities_context = ""
            if entities:
                entity_lines = []
                if 'brand' in entities:
                    entity_lines.append(f"Th∆∞∆°ng hi·ªáu: {entities['brand']}")
                if 'gender' in entities:
                    entity_lines.append(f"Gi·ªõi t√≠nh: {entities['gender']}")
                if 'max_price' in entities:
                    entity_lines.append(f"Gi√° t·ªëi ƒëa: {entities['max_price']:,} VND")
                if 'min_price' in entities:
                    entity_lines.append(f"Gi√° t·ªëi thi·ªÉu: {entities['min_price']:,} VND")
                if 'color' in entities:
                    entity_lines.append(f"M√†u s·∫Øc: {entities['color']}")
                if 'category' in entities:
                    entity_lines.append(f"Lo·∫°i: {entities['category']}")
                if 'purpose' in entities:
                    entity_lines.append(f"M·ª•c ƒë√≠ch: {entities['purpose']}")
                if entity_lines:
                    entities_context = "\n\nTh√¥ng tin kh√°ch y√™u c·∫ßu:\n" + ", ".join(entity_lines)
            
            # Prompt ChatGPT v3 - FOCUS ON LINKS CONTROL
            # Note: Backend s·∫Ω quy·∫øt ƒë·ªãnh khi n√†o th√™m links d·ª±a v√†o intent
            prompt = f"""You are Footy, an AI shopping assistant for FootFashion.

Personality: friendly, Gen Z, t·ª± nhi√™n, kh√¥ng m√°y m√≥c, kh√¥ng l·∫∑p.

üì¶ TH√îNG TIN S·∫¢N PH·∫®M:
{product_context}

üéâ KHUY·∫æN M√ÉI:
{promotion_context}

üí¨ H·ªòI THO·∫†I TR∆Ø·ªöC:
{conversation_context}{prefs_context}{entities_context}

‚ùì USER: "{message}"

üéØ RULES FOR LINKS (TU√ÇN TH·ª¶ NGHI√äM NG·∫∂T):

1. **Only provide product links when EXPLICITLY requested**
   - User ph·∫£i n√≥i r√µ: "Cho t√¥i link X", "G·ª£i √Ω 2 s·∫£n ph·∫©m", "Link Air Max 270", "T√¨m gi√†y Nike", "Show gi√†y"
   - N·∫øu user CH·ªà h·ªèi v·ªÅ t√≠nh nƒÉng, size, m√†u, gi√° ‚Üí KH√îNG show link
   - VD: "Gi√†y n√†y ch·ªëng n∆∞·ªõc kh√¥ng?" ‚Üí Tr·∫£ l·ªùi v·ªÅ ch·ªëng n∆∞·ªõc, KH√îNG k√®m link

2. **Exact requested products only**
   - User h·ªèi 1 s·∫£n ph·∫©m ‚Üí tr·∫£ 1 link ƒë√∫ng s·∫£n ph·∫©m
   - User h·ªèi 2 s·∫£n ph·∫©m ‚Üí tr·∫£ 2 link ƒë√∫ng, KH√îNG th√™m
   - KH√îNG show products m·∫∑c ƒë·ªãnh hay g·ª£i √Ω lung tung

3. **Alternatives**
   - N·∫øu s·∫£n ph·∫©m kh√¥ng c√≥ ‚Üí ch·ªâ g·ª£i √Ω 1-2 s·∫£n ph·∫©m g·∫ßn nh·∫•t, KH√îNG nhi·ªÅu h∆°n

4. **Maintain context**
   - User h·ªèi v·ªÅ "n√≥", "ƒë√¥i n√†y" ‚Üí hi·ªÉu l√† s·∫£n ph·∫©m cu·ªëi c√πng
   - KH√îNG t·ª± ƒë·ªông show link khi h·ªèi follow-up v·ªÅ t√≠nh nƒÉng

5. **No spam**
   - KH√îNG show link sau m·ªói c√¢u tr·∫£ l·ªùi
   - Ch·ªâ show khi user explicitly y√™u c·∫ßu ho·∫∑c alternatives c·∫ßn g·ª£i √Ω

üìù S·∫¢N PH·∫®M M·∫™U:
- Nike Air Max 270: 2.58tr, size 36-38, ƒêen/Xanh, ch·∫°y nh·∫π, ko ch·ªëng n∆∞·ªõc
- Nike Air Jordan: 12.3tr, size 38-39, Xanh/N√¢u, da t·ªïng h·ª£p, h·∫°n ch·∫ø n∆∞·ªõc
- Adidas Ultraboost: 3.9tr, size 39-43, Tr·∫Øng/ƒêen, ch·∫°y √™m, ch·ªëng n∆∞·ªõc nh·∫π
- Puma Velocity: 2.3tr, size 40-44, X√°m, ch·∫°y t·ªët, tho√°ng kh√≠

üí° Style: Ng·∫Øn, r√µ, Gen Z, √≠t emoji (max 1-2), kh√¥ng reset conversation.

üö´ CRITICAL - KHI KH√îNG ƒê∆Ø·ª¢C SHOW LINKS:
- User h·ªèi: "Gi√†y n√†y ch·ªëng n∆∞·ªõc kh√¥ng?" ‚Üí Tr·∫£ l·ªùi v·ªÅ ch·ªëng n∆∞·ªõc, KH√îNG show link
- User h·ªèi: "C√≥ size 40 kh√¥ng?" ‚Üí Tr·∫£ l·ªùi v·ªÅ size, KH√îNG show link
- User h·ªèi: "C√≥ m√†u ƒëen kh√¥ng?" ‚Üí Tr·∫£ l·ªùi v·ªÅ m√†u, KH√îNG show link
- User h·ªèi: "Gi√° bao nhi√™u?" ‚Üí Tr·∫£ l·ªùi gi√°, KH√îNG show link

‚úÖ CH·ªà SHOW LINKS KHI:
- User n√≥i: "T√¨m gi√†y", "G·ª£i √Ω", "Cho t√¥i link", "Show s·∫£n ph·∫©m", "Xem gi√†y"
- S·∫£n ph·∫©m kh√¥ng c√≥ ‚Üí g·ª£i √Ω alternatives (1-2 s·∫£n ph·∫©m)

Tr·∫£ l·ªùi (ng·∫Øn, t·ª± nhi√™n, KH√îNG spam links):"""

            # G·ªçi Gemini Flash API v·ªõi timeout ng·∫Øn
            response = self.model.generate_content(prompt)
            
            if response and response.text:
                ai_response = response.text.strip()
            else:
                return self._get_enhanced_fallback_response(intent, context, message, entities)
            
            # ‚úÖ FIX 1, 3: Check n·∫øu n√™n show product links + Extract s·ªë l∆∞·ª£ng user y√™u c·∫ßu
            message_lower = message.lower()
            should_show_links = self._should_show_product_links(message, intent, context)
            requested_count = self._extract_requested_count(message)  # ‚úÖ FIX 3: Detect s·ªë l∆∞·ª£ng user y√™u c·∫ßu
            
            # Legacy checks (keep for compatibility)
            image_related_keywords = ['h√¨nh ·∫£nh', 'hinh anh', '·∫£nh', 'anh', 'image', 'photo', 'picture', 'h√¨nh', 'hin']
            is_asking_about_images = any(keyword in message_lower for keyword in image_related_keywords)
            
            link_related_keywords = ['link', 'li√™n k·∫øt', 'lien ket', 'g·ª≠i link', 'gui link', 'cho link', 'c√≥ link', 'co link', 'link s·∫£n ph·∫©m', 'link san pham', 'ƒë∆∞·ªùng link', 'duong link', 'url']
            is_asking_for_links = any(keyword in message_lower for keyword in link_related_keywords)
            
            # OVERRIDE: N·∫øu h·ªèi v·ªÅ images/links ‚Üí considered as explicit request
            if is_asking_about_images or is_asking_for_links:
                should_show_links = True
                # N·∫øu user h·ªèi "cho t√¥i link" ‚Üí c√≥ th·ªÉ l√† 1 s·∫£n ph·∫©m
                if 'link' in message_lower and not requested_count:
                    requested_count = 1
            
            # Check if we should ask for confirmation before showing products
            should_ask_confirmation = self._should_ask_product_confirmation(message, intent, context)
            
            # Check if user is asking about images/links in context of products
            # If last intent was product_search/recommendation, show products even when asking for images/links
            has_product_context = False
            if context and len(context) > 0:
                last_intent = context[-1].get('intent', '')
                if last_intent in ['product_search', 'recommendation']:
                    has_product_context = True
            
            # ‚úÖ NEW LOGIC: Ch·ªâ show links khi should_show_links = True
            # N·∫øu user ch·ªâ h·ªèi v·ªÅ features (size, m√†u, ch·ªëng n∆∞·ªõc) ‚Üí KH√îNG show links
            if not should_show_links:
                return {
                    'content': ai_response,
                    'products': [],  # Kh√¥ng show products khi user ch·ªâ h·ªèi v·ªÅ features
                    'promotions': []
                }
            
            # If asking for links (with or without product context), ALWAYS show products directly - NO confirmation
            if is_asking_for_links:
                # User is asking for links of products mentioned before - show immediately
                # QUAN TR·ªåNG: ∆Øu ti√™n s·ª≠ d·ª•ng last message ƒë·ªÉ gi·ªØ l·∫°i filters (brand, gender, etc.)
                products_data = []
                if context and len(context) > 0:
                    last_message = context[-1].get('message', '')
                    if last_message:
                        # ∆Øu ti√™n 1: S·ª≠ d·ª•ng last message tr∆∞·ªõc (ch·ª©a brand filter)
                        products_data = self._get_relevant_products(last_message, 'product_search')
                        logger.info(f"Getting products from last message (for links): {last_message[:50]}... Found {len(products_data)} products")
                        
                        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c, th·ª≠ combine v·ªõi current message
                        if not products_data:
                            search_message = f"{last_message} {message}"
                            products_data = self._get_relevant_products(search_message, 'product_search')
                            logger.info(f"Trying combined message for links. Found {len(products_data)} products")
                
                # N·∫øu v·∫´n kh√¥ng c√≥, th·ª≠ t√¨m trong to√†n b·ªô context (t√¨m brand trong c√°c message tr∆∞·ªõc)
                if not products_data and context and len(context) > 0:
                    # T√¨m brand trong c√°c message tr∆∞·ªõc ƒë√≥
                    for conv in reversed(context[-3:]):  # Xem 3 message g·∫ßn nh·∫•t
                        prev_message = conv.get('message', '').lower()
                        brands = ['nike', 'adidas', 'puma', 'vans', 'converse']
                        for brand in brands:
                            if brand in prev_message:
                                products_data = self._get_relevant_products(conv.get('message', ''), 'product_search')
                                if products_data:
                                    logger.info(f"Found products from previous context message with brand '{brand}' for links. Found {len(products_data)} products")
                                    break
                        if products_data:
                            break
                
                # N·∫øu c√≥ product context nh∆∞ng kh√¥ng t√¨m ƒë∆∞·ª£c products, kh√¥ng fallback (gi·ªØ l·∫°i filters)
                # N·∫øu KH√îNG c√≥ product context, fallback v·ªÅ top products
                if not products_data:
                    if has_product_context:
                        logger.warning(f"No products found for link request with product context. Last message: {context[-1].get('message', '')[:50] if context else 'N/A'}")
                    else:
                        # Kh√¥ng c√≥ product context, l·∫•y top products
                        products_data = self._get_relevant_products('', 'recommendation')
                        logger.info(f"No product context for link request, using top products. Found {len(products_data)} products")
                
                # Th√™m links v√†o content (CH·ªà khi should_show_links = True)
                if products_data and should_show_links:
                    links_text = self._format_products_as_links(products_data)
                    ai_response = ai_response + links_text
                elif not products_data and should_show_links:
                    # N·∫øu user y√™u c·∫ßu xem nh∆∞ng kh√¥ng c√≥ products
                    ai_response = ai_response + "\n\nHi·ªán kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p. B·∫°n th·ª≠ t·ª´ kh√≥a kh√°c nha"
                
                promotions_data = self._get_relevant_promotions(context[-1].get('message', '') if context else message, 'product_search')
                return {
                    'content': ai_response,
                    'products': [],  # Kh√¥ng tr·∫£ v·ªÅ products array n·ªØa, ch·ªâ tr·∫£ v·ªÅ links trong content
                    'promotions': promotions_data
                }
            
            # ‚úÖ SIMPLIFIED LOGIC: Show products based on should_show_links flag
            # Ch·ªâ show khi user EXPLICITLY request
            if should_show_links:
                # Get products based on intent
                search_message = message
                if (is_asking_about_images or is_asking_for_links) and context and len(context) > 0:
                    last_message = context[-1].get('message', '')
                    if last_message:
                        search_message = f"{last_message} {message}"
                
                # ‚úÖ FIX 3, 4: Truy·ªÅn requested_count v√† context v√†o
                products_data = self._get_relevant_products(
                    search_message, 
                    intent if intent in ['product_search', 'recommendation'] else 'product_search',
                    requested_count=requested_count,  # ‚úÖ FIX 3: Tu√¢n th·ªß s·ªë l∆∞·ª£ng
                    context=context  # ‚úÖ FIX 4: Context-aware
                )
                
                # Th√™m links v√†o content
                if products_data:
                    links_text = self._format_products_as_links(products_data)
                    ai_response = ai_response + links_text
                    logger.info(f"‚úÖ FIX 1, 3: Showing {len(products_data)} products (user requested: {requested_count})")
                elif is_asking_for_links:
                    ai_response = ai_response + "\n\nHi·ªán kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p. B·∫°n th·ª≠ t·ª´ kh√≥a kh√°c nha"
                
                promotions_data = self._get_relevant_promotions(search_message, intent if intent in ['product_search', 'recommendation'] else 'product_search')
                
                return {
                    'content': ai_response,
                    'products': [],
                    'promotions': promotions_data
                }
            else:
                # ‚úÖ FIX 1: User ch·ªâ h·ªèi v·ªÅ features, KH√îNG show products
                logger.info(f"‚úÖ FIX 1: Not showing links (feature question only)")
                return {
                    'content': ai_response,
                    'products': [],
                    'promotions': []
                }
                
        except Exception as e:
            logger.error(f"Gemini Flash API error: {e}")
            error_str = str(e).lower()
            
            # Improved error handling v·ªõi c√°c lo·∫°i l·ªói kh√°c nhau
            if "quota" in error_str or "429" in error_str or "rate limit" in error_str:
                logger.warning("Gemini API quota exceeded, using enhanced fallback response")
                return self._get_enhanced_fallback_response(intent, context, message, entities)
            elif "api key" in error_str or "authentication" in error_str:
                logger.error("Gemini API key invalid, using fallback response")
                return self._get_enhanced_fallback_response(intent, context, message, entities)
            elif "timeout" in error_str or "timed out" in error_str:
                logger.warning("Gemini API timeout, using fallback response")
                return self._get_enhanced_fallback_response(intent, context, message, entities)
            else:
                logger.error(f"Unknown Gemini API error: {e}")
                return self._get_enhanced_fallback_response(intent, context, message, entities)
    
    def generate_ai_response(self, message: str, intent: str, context: List[Dict] = None, sentiment: Dict = None, confidence: float = 0.0) -> str:
        """Wrapper method ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©"""
        response_data = self.generate_intelligent_response(message, intent, context)
        if isinstance(response_data, dict):
            return response_data.get('content', '')
        return response_data
    
    def _should_show_product_links(self, message: str, intent: str, context: List[Dict] = None) -> bool:
        """
        X√°c ƒë·ªãnh c√≥ n√™n show product links kh√¥ng
        CH·ªà show khi user EXPLICITLY y√™u c·∫ßu - STRICT MODE
        Returns True n·∫øu c·∫ßn show, False n·∫øu ch·ªâ tr·∫£ l·ªùi text
        """
        message_lower = message.lower()
        
        # Keywords y√™u c·∫ßu xem s·∫£n ph·∫©m EXPLICITLY (ph·∫£i c√≥)
        explicit_request_keywords = [
            't√¨m', 'tim', 'find', 'search',
            'g·ª£i √Ω', 'goi y', 'suggest', 'recommend',
            'cho t√¥i', 'cho toi', 'show', 'xem',
            'link', 's·∫£n ph·∫©m', 'san pham',
            'ƒë·ªÅ xu·∫•t', 'de xuat', 'mu·ªën xem', 'muon xem',
            'c√≥ gi√†y', 'co giay', 'c√≥ s·∫£n ph·∫©m', 'co san pham'
        ]
        
        # Keywords h·ªèi v·ªÅ FEATURES (KH√îNG c·∫ßn show products)
        feature_question_keywords = [
            'ch·ªëng n∆∞·ªõc', 'chong nuoc', 'waterproof',
            'ƒë·ªô b·ªÅn', 'do ben', 'durability', 'b·ªÅn',
            'fit ch√¢n', 'fit chan', '√¥m ch√¢n', 'om chan',
            'size', 'c·ª°', 'co', 'k√≠ch c·ª°', 'kich co',
            'm√†u', 'mau', 'color', 'm√†u s·∫Øc',
            'gi√°', 'gia', 'price', 'bao nhi√™u',
            'ch·∫•t li·ªáu', 'chat lieu', 'material',
            'n·∫∑ng', 'nang', 'weight', 'nh·∫π', 'nhe',
            'c√≤n', 'con', 'c√≥ kh√¥ng', 'co khong'
        ]
        
        # Context pronouns (c·∫ßn check xem c√≥ context kh√¥ng)
        context_pronouns = ['n√≥', 'no', 'ƒë√¥i n√†y', 'doi nay', 'gi√†y n√†y', 'giay nay', 'c√°i n√†y', 'cai nay']
        
        # ‚úÖ FIX 1: N·∫øu l√† follow-up question v·ªÅ features ‚Üí KH√îNG show
        if any(keyword in message_lower for keyword in feature_question_keywords):
            # N·∫øu KH√îNG c√≥ explicit request keyword ‚Üí kh√¥ng show products
            if not any(keyword in message_lower for keyword in explicit_request_keywords):
                return False
        
        # ‚úÖ FIX 4: N·∫øu l√† context pronoun ("n√≥", "ƒë√¥i n√†y") m√† KH√îNG c√≥ explicit request ‚Üí KH√îNG show
        if any(pronoun in message_lower for pronoun in context_pronouns):
            # Ch·ªâ show n·∫øu c√≥ explicit request keyword
            if not any(keyword in message_lower for keyword in explicit_request_keywords):
                return False
        
        # Check n·∫øu user EXPLICITLY request products
        if any(keyword in message_lower for keyword in explicit_request_keywords):
            return True
        
        # Check n·∫øu intent l√† product_search ho·∫∑c recommendation ‚Üí show (nh∆∞ng ch·ªâ khi c√≥ explicit request)
        if intent in ['product_search', 'recommendation']:
            # Ch·ªâ show n·∫øu c√≥ explicit request keyword
            if any(keyword in message_lower for keyword in explicit_request_keywords):
                return True
        
        # Default: KH√îNG show (STRICT MODE)
        return False
    
    def _extract_requested_count(self, message: str) -> Optional[int]:
        """
        Tr√≠ch xu·∫•t s·ªë l∆∞·ª£ng s·∫£n ph·∫©m user y√™u c·∫ßu
        Returns: s·ªë l∆∞·ª£ng (1, 2, 3...) ho·∫∑c None n·∫øu kh√¥ng r√µ
        """
        message_lower = message.lower()
        
        # Patterns ƒë·ªÉ detect s·ªë l∆∞·ª£ng
        patterns = [
            r'(?:cho t√¥i|cho toi|g·ª£i √Ω|goi y|ƒë·ªÅ xu·∫•t|de xuat|show|xem)\s*(?:cho t√¥i|cho toi)?\s*(\d+)\s*(?:s·∫£n ph·∫©m|san pham|ƒë√¥i|doi|gi√†y|giay|link)',
            r'(\d+)\s*(?:s·∫£n ph·∫©m|san pham|ƒë√¥i|doi|gi√†y|giay|link)',
            r'(?:m·ªôt|mot|1)\s*(?:s·∫£n ph·∫©m|san pham|ƒë√¥i|doi|gi√†y|giay)',
            r'(?:hai|2)\s*(?:s·∫£n ph·∫©m|san pham|ƒë√¥i|doi|gi√†y|giay)',
            r'(?:ba|3)\s*(?:s·∫£n ph·∫©m|san pham|ƒë√¥i|doi|gi√†y|giay)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, message_lower)
            if match:
                if match.group(1):
                    return int(match.group(1))
                # Check text numbers
                if 'm·ªôt' in message_lower or 'mot' in message_lower:
                    return 1
                elif 'hai' in message_lower:
                    return 2
                elif 'ba' in message_lower:
                    return 3
        
        # Check explicit single product request
        single_product_keywords = ['m·ªôt ƒë√¥i', 'mot doi', '1 ƒë√¥i', '1 doi', 'link', 's·∫£n ph·∫©m n√†y', 'san pham nay']
        if any(keyword in message_lower for keyword in single_product_keywords):
            # N·∫øu c√≥ t√™n s·∫£n ph·∫©m c·ª• th·ªÉ ‚Üí 1
            product_names = ['air max', 'jordan', 'ultraboost', 'velocity', 'superstar', 'nmd']
            if any(name in message_lower for name in product_names):
                return 1
        
        return None
    
    def _should_ask_product_confirmation(self, message: str, intent: str, context: List[Dict] = None) -> bool:
        """
        X√°c ƒë·ªãnh c√≥ n√™n h·ªèi user tr∆∞·ªõc khi show products kh√¥ng
        Returns True n·∫øu c·∫ßn h·ªèi, False n·∫øu show products ngay
        """
        message_lower = message.lower()
        
        # Case 0: User ƒëang y√™u c·∫ßu xem h√¨nh ·∫£nh/link ‚Üí KH√îNG h·ªèi x√°c nh·∫≠n, show ngay
        image_keywords = ['h√¨nh ·∫£nh', 'hinh anh', '·∫£nh', 'anh', 'image', 'photo', 'picture', 'h√¨nh', 'hin', 'xem h√¨nh', 'cho xem']
        link_keywords = ['link', 'li√™n k·∫øt', 'lien ket', 'g·ª≠i link', 'gui link', 'cho link', 'c√≥ link', 'co link', 'link s·∫£n ph·∫©m', 'link san pham', 'ƒë∆∞·ªùng link', 'duong link', 'url']
        if any(keyword in message_lower for keyword in image_keywords) or any(keyword in message_lower for keyword in link_keywords):
            # N·∫øu c√≥ product context ho·∫∑c intent l√† product_search/recommendation ‚Üí show ngay
            if context and len(context) > 0:
                last_intent = context[-1].get('intent', '')
                if last_intent in ['product_search', 'recommendation']:
                    return False  # Show products immediately
            if intent in ['product_search', 'recommendation']:
                return False  # Show products immediately
        
        # Case 1: User ƒë√£ confirm (n√≥i 'c√≥', 'xem', 'show', etc.)
        confirmation_keywords = [
            'c√≥', 'xem', 'show', 'cho xem', 'mu·ªën xem', 'mu·ªën', 
            'ƒë∆∞·ª£c', 'ok', 'oke', 'yes', 'yeah', 'yep', '·ª´', 'uh', 
            'ƒë·ªìng √Ω', 'cho t√¥i xem', 'hi·ªÉn th·ªã', 'list'
        ]
        if any(keyword in message_lower for keyword in confirmation_keywords):
            # Check context: n·∫øu c√¢u tr∆∞·ªõc ƒë√≥ l√† pending products ‚Üí show ngay
            if context and len(context) > 0:
                last_conv = context[-1]
                if last_conv.get('response', '').find('B·∫°n c√≥ mu·ªën xem') != -1:
                    return False  # User confirmed, show products
        
        # Case 2: User t·ª´ ch·ªëi (n√≥i 'kh√¥ng', 'kh√¥ng mu·ªën', etc.)
        rejection_keywords = ['kh√¥ng', 'ko', 'k', 'no', 'ch∆∞a', 'th√¥i', 'kh√¥ng c·∫ßn']
        if any(keyword == message_lower or keyword + ' ' in message_lower for keyword in rejection_keywords):
            return False  # Don't show products, user rejected
        
        # Case 3: First time product search/recommendation ‚Üí Ask first
        if intent in ['product_search', 'recommendation']:
            # Check if this is a follow-up or first request
            if context and len(context) > 0:
                last_intent = context[-1].get('intent', '')
                # If last message was asking for confirmation, don't ask again
                if last_intent in ['product_search', 'recommendation']:
                    return False  # Already in product flow, show directly
            return True  # First request, ask confirmation
        
        # Case 4: Other intents (greeting, help, etc.) ‚Üí Don't show products
        return False
    
    def _get_relevant_products(self, message: str, intent: str, user_id: str = None, requested_count: Optional[int] = None, context: List[Dict] = None) -> List[Dict]:
        """
        L·∫•y s·∫£n ph·∫©m li√™n quan v·ªõi Advanced Entity-Based Filtering
        ‚úÖ FIX 3: Tu√¢n th·ªß s·ªë l∆∞·ª£ng user y√™u c·∫ßu (1:1, 2:2)
        ‚úÖ FIX 4: Context-aware cho "n√≥", "ƒë√¥i n√†y"
        """
        try:
            message_lower = message.lower()
            
            # ‚úÖ FIX 4: Context mapping cho "n√≥", "ƒë√¥i n√†y"
            context_pronouns = ['n√≥', 'no', 'ƒë√¥i n√†y', 'doi nay', 'gi√†y n√†y', 'giay nay', 'c√°i n√†y', 'cai nay']
            is_context_pronoun = any(pronoun in message_lower for pronoun in context_pronouns)
            
            # N·∫øu l√† context pronoun, t√¨m s·∫£n ph·∫©m t·ª´ conversation tr∆∞·ªõc
            if is_context_pronoun and context and len(context) > 0:
                # T√¨m s·∫£n ph·∫©m cu·ªëi c√πng ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn
                for conv in reversed(context[-5:]):  # Xem 5 message g·∫ßn nh·∫•t
                    last_message = conv.get('message', '')
                    if last_message:
                        # Extract entities t·ª´ last message
                        last_entities = self.nlp_processor.extract_entities(last_message)
                        if last_entities:
                            # S·ª≠ d·ª•ng entities t·ª´ last message ƒë·ªÉ t√¨m s·∫£n ph·∫©m
                            message = last_message  # Override message v·ªõi last message
                            logger.info(f"‚úÖ FIX 4: Context pronoun detected, using last message: {last_message[:50]}")
                            break
            
            # L·∫•y s·∫£n ph·∫©m d·ª±a tr√™n intent
            if intent in ['product_search', 'recommendation']:
                # Extract entities from message
                entities = self.nlp_processor.extract_entities(message)
                
                # T√¨m ki·∫øm s·∫£n ph·∫©m d·ª±a tr√™n entities v·ªõi scoring
                from django.db.models import Case, When, Value, IntegerField
                
                # Build filters using entities - use AND logic
                filters = Q()  # Start with empty Q for AND conditions
                score_cases = []
                has_filters = False
                
                # Brand filter (MUST match if specified)
                if 'brand' in entities:
                    brand = entities['brand']
                    filters &= Q(brand__name__icontains=brand)  # AND condition
                    score_cases.append(When(brand__name__icontains=brand, then=Value(10)))
                    has_filters = True
                    logger.info(f"üéØ Brand filter: {brand}")
                
                # Gender filter (MUST match if specified)
                if 'gender' in entities:
                    gender = entities['gender']
                    filters &= Q(gender__name__icontains=gender)  # AND condition
                    score_cases.append(When(gender__name__icontains=gender, then=Value(8)))
                    has_filters = True
                    logger.info(f"üéØ Gender filter: {gender}")
                
                # Category filter (MUST match if specified)
                if 'category' in entities:
                    category = entities['category']
                    filters &= Q(category__name__icontains=category)  # AND condition
                    score_cases.append(When(category__name__icontains=category, then=Value(7)))
                    has_filters = True
                    logger.info(f"üéØ Category filter: {category}")
                
                # Price filter (MUST match if specified)
                if 'max_price' in entities:
                    max_price = entities['max_price']
                    filters &= Q(price__lte=max_price)  # AND condition
                    score_cases.append(When(price__lte=max_price, then=Value(5)))
                    has_filters = True
                    logger.info(f"üéØ Max price filter: {max_price}")
                
                if 'min_price' in entities:
                    min_price = entities['min_price']
                    filters &= Q(price__gte=min_price)  # AND condition
                    score_cases.append(When(price__gte=min_price, then=Value(5)))
                    has_filters = True
                    logger.info(f"üéØ Min price filter: {min_price}")
                
                # Size filter (optional, adds bonus score if match)
                if 'size' in entities:
                    size = entities['size']
                    score_cases.append(When(sizes__value=size, then=Value(3)))
                    logger.info(f"üéØ Size preference: {size}")
                
                # Color filter (optional, adds bonus score if match)
                if 'color' in entities:
                    color = entities['color']
                    score_cases.append(When(colors__value__icontains=color, then=Value(3)))
                    logger.info(f"üéØ Color preference: {color}")
                
                # Quality keywords scoring (bonus points)
                if any(word in message_lower for word in ['t·ªët', 'ch·∫•t l∆∞·ª£ng', 'ƒë·∫πp', 'hay', 'b√°n ch·∫°y']):
                    score_cases.append(When(sales_count__gt=10, then=Value(6)))
                
                # Purpose-based scoring
                if 'purpose' in entities:
                    purpose = entities['purpose']
                    if purpose == 'running':
                        score_cases.append(When(category__name__icontains='sneaker', then=Value(4)))
                    elif purpose == 'casual':
                        score_cases.append(When(category__name__icontains='casual', then=Value(4)))
                    logger.info(f"üéØ Purpose: {purpose}")
                
                # Query products with AND logic
                if has_filters:
                    products = Product.objects.select_related('brand', 'category', 'gender').prefetch_related(
                        'sizes', 'colors', 'images'
                    ).filter(filters).distinct()  # All conditions must match
                    
                    logger.info(f"üìä Querying products with {len([k for k in entities.keys()])} filters. Total found: {products.count()}")
                    
                    # ‚úÖ FIX 3: Tu√¢n th·ªß s·ªë l∆∞·ª£ng user y√™u c·∫ßu
                    # Default: 3 s·∫£n ph·∫©m, nh∆∞ng n·∫øu user y√™u c·∫ßu 1 ho·∫∑c 2 ‚Üí ch·ªâ show ƒë√∫ng s·ªë ƒë√≥
                    limit = requested_count if requested_count and requested_count <= 3 else 3
                    
                    # Apply scoring
                    if score_cases:
                        products = products.annotate(
                            relevance_score=Case(
                                *score_cases,
                                default=Value(0),
                                output_field=IntegerField()
                            )
                        ).order_by('-relevance_score', '-sales_count', '-id')[:limit]
                    else:
                        products = products.order_by('-sales_count', '-id')[:limit]
                    
                    logger.info(f"‚úÖ FIX 3: User requested {requested_count}, showing {limit} products")
                else:
                    # Recommendation mode: l·∫•y top trending products
                    logger.info(f"üìä No specific filters, using recommendation mode (top sellers)")
                    limit = requested_count if requested_count and requested_count <= 3 else 3
                    products = Product.objects.select_related('brand', 'category', 'gender').prefetch_related(
                        'sizes', 'colors', 'images'
                    ).order_by('-sales_count', '-id')[:limit]
                
                # Convert to frontend format
                # ‚úÖ FIX 2: ƒê·∫£m b·∫£o link th·∫≠t t·ª´ database (kh√¥ng fake)
                products_data = []
                for product in products:
                    # ‚úÖ FIX 2: Link th·∫≠t t·ª´ database - format: /product/{id}
                    # ƒê·∫£m b·∫£o product.id t·ªìn t·∫°i v√† h·ª£p l·ªá
                    if product.id:
                        product_link = f"/product/{product.id}"  # Link th·∫≠t, click ƒë∆∞·ª£c
                    else:
                        logger.warning(f"‚ö†Ô∏è Product {product.name} kh√¥ng c√≥ ID, skip")
                        continue
                    
                    products_data.append({
                        'id': product.id,
                        'name': product.name,
                        'brand': product.brand.name if product.brand else 'Unknown',
                        'price': float(product.price),
                        'image': None,  # No images in response
                        'link': product_link,  # ‚úÖ Link th·∫≠t t·ª´ database
                        'description': product.description[:100] if product.description else '',
                        'sales_count': product.sales_count
                    })
                
                # Log ƒë·ªÉ debug
                if products_data:
                    logger.info(f"‚úÖ Returning {len(products_data)} products")
                else:
                    logger.warning(f"‚ö†Ô∏è No products found for filters: {entities}")
                
                return products_data
            
            return []
            
        except Exception as e:
            logger.error(f"‚ùå Error getting relevant products: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _format_products_as_links(self, products_data: List[Dict]) -> str:
        """
        Format products th√†nh markdown links ƒë·ªÉ th√™m v√†o content
        ‚úÖ FIX 2: ƒê·∫£m b·∫£o ch·ªâ d√πng link th·∫≠t t·ª´ database, kh√¥ng fake
        """
        if not products_data:
            return ""
        
        links_text = "\n\nüîó Link s·∫£n ph·∫©m:\n"
        for i, product in enumerate(products_data, 1):
            product_name = product.get('name', 'S·∫£n ph·∫©m')
            product_link = product.get('link', '')
            product_id = product.get('id')
            
            # ‚úÖ FIX 2: ƒê·∫£m b·∫£o link th·∫≠t t·ª´ database
            # N·∫øu kh√¥ng c√≥ link ho·∫∑c link kh√¥ng h·ª£p l·ªá ‚Üí t·∫°o link th·∫≠t t·ª´ ID
            if not product_link or product_link == '#' or not product_link.startswith('/product/'):
                if product_id:
                    # T·∫°o link th·∫≠t t·ª´ database ID
                    product_link = f"/product/{product_id}"
                    logger.info(f"‚úÖ FIX 2: Generated real link from DB: {product_link}")
                else:
                    # N·∫øu kh√¥ng c√≥ ID ‚Üí skip s·∫£n ph·∫©m n√†y
                    logger.warning(f"‚ö†Ô∏è FIX 2: Product {product_name} kh√¥ng c√≥ ID, skip")
                    continue
            
            # ƒê·∫£m b·∫£o link l√† relative path (kh√¥ng c√≥ domain)
            if product_link.startswith('http'):
                # Extract path t·ª´ full URL
                from urllib.parse import urlparse
                parsed = urlparse(product_link)
                product_link = parsed.path
            
            # ‚úÖ FIX 2: Validate link format (ph·∫£i l√† /product/{id})
            if not product_link.startswith('/product/'):
                logger.warning(f"‚ö†Ô∏è FIX 2: Invalid link format: {product_link}, skip")
                continue
            
            # Format d∆∞·ªõi d·∫°ng markdown link ƒë·ªÉ frontend c√≥ th·ªÉ parse v√† render th√†nh clickable
            links_text += f"{i}. [{product_name}]({product_link})\n"
        
        return links_text
    
    def _get_relevant_promotions(self, message: str, intent: str) -> List[Dict]:
        """L·∫•y promotions li√™n quan d·ª±a tr√™n message v√† intent"""
        try:
            if intent == 'promotion' or 'khuy·∫øn m√£i' in message.lower() or 'sale' in message.lower():
                now = timezone.now()
                promotions = Promotion.objects.filter(
                    is_active=True,
                    start_date__lte=now,
                    end_date__gte=now
                ).order_by('-discount_percentage')[:2]
                
                promotions_data = []
                for promo in promotions:
                    promotions_data.append({
                        'code': promo.code,
                        'discount_percentage': promo.discount_percentage,
                        'description': promo.description or f"Gi·∫£m {promo.discount_percentage}%",
                        'end_date': promo.end_date.isoformat() if promo.end_date else None
                    })
                
                return promotions_data
            
            return []
            
        except Exception as e:
            logger.error(f"Error getting relevant promotions: {e}")
            return []
    
    def _get_enhanced_fallback_response(self, intent: str, context: List[Dict] = None, message: str = "", entities: Dict = None) -> Dict[str, Any]:
        """
        Ph·∫£n h·ªìi d·ª± ph√≤ng n√¢ng cao khi Gemini API l·ªói
        QUAN TR·ªåNG: Tr·∫£ l·ªùi ngay, kh√¥ng h·ªèi l·∫°i nhi·ªÅu
        """
        if not entities:
            entities = self.nlp_processor.extract_entities(message) if message else {}
        
        # Enhanced responses v·ªõi th√¥ng tin t·ª´ entities - NG·∫ÆN G·ªåN, TR·∫¢ L·ªúI NGAY
        if intent == 'product_search':
            # ‚úÖ FIX 3: Extract s·ªë l∆∞·ª£ng user y√™u c·∫ßu
            requested_count = self._extract_requested_count(message) if message else None
            
            # Lu√¥n t√¨m ki·∫øm v√† tr·∫£ v·ªÅ s·∫£n ph·∫©m, kh√¥ng h·ªèi l·∫°i
            products_data = self._get_relevant_products(message, intent, requested_count=requested_count, context=context)
            
            if products_data:
                links_text = self._format_products_as_links(products_data)
                
                # T·∫°o c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, Gen Z style, √≠t emoji
                if entities.get('brand') and entities.get('gender'):
                    content = f"ƒê√¢y l√† {entities['brand']} {entities['gender']} m√¨nh t√¨m ƒë∆∞·ª£c üëü"
                elif entities.get('brand'):
                    content = f"M·∫•y ƒë√¥i {entities['brand']} n√†y b·∫°n xem nha"
                elif entities.get('gender'):
                    content = f"Gi√†y {entities['gender']} hot nh·∫•t ƒë√¢y"
                elif entities.get('max_price'):
                    price_text = f"{entities['max_price']:,}" if entities['max_price'] >= 1000000 else f"{entities['max_price']//1000}k"
                    content = f"Gi√†y d∆∞·ªõi {price_text} ƒë√¢y n√®"
                else:
                    content = "Top gi√†y b√°n ch·∫°y ƒë√¢y"
                
                content += f"\n\n{links_text}"
                return {
                    'content': content,
                    'products': [],
                    'promotions': []
                }
            else:
                # ‚úÖ FIX 5: Kh√¥ng t√¨m ƒë∆∞·ª£c s·∫£n ph·∫©m ‚Üí G·ª£i √Ω CH·ªà 1-2 alternatives (KH√îNG 3, KH√îNG 5)
                content = "S·∫£n ph·∫©m n√†y h·∫øt r·ªìi b·∫°n. ƒê·ªÉ m√¨nh g·ª£i √Ω 1-2 ƒë√¥i t∆∞∆°ng t·ª± nha"
                # L·∫•y CH·ªà 1-2 top products l√†m alternatives (KH√îNG nhi·ªÅu h∆°n)
                alt_products = self._get_relevant_products('', 'recommendation', requested_count=2, context=context)[:2]  # ‚úÖ FIX 5: CH·ªà 2 s·∫£n ph·∫©m
                if alt_products:
                    links_text = self._format_products_as_links(alt_products)
                    content += f"\n\n{links_text}"
                    logger.info(f"‚úÖ FIX 5: Showing {len(alt_products)} alternatives (limited to 1-2)")
                return {
                    'content': content,
                    'products': [],
                    'promotions': []
                }
        
        elif intent == 'recommendation':
            # ‚úÖ FIX 3: Extract s·ªë l∆∞·ª£ng user y√™u c·∫ßu
            requested_count = self._extract_requested_count(message) if message else None
            products_data = self._get_relevant_products('', 'recommendation', requested_count=requested_count, context=context)
            if products_data:
                links_text = self._format_products_as_links(products_data)
                content = f"Top gi√†y hot nh·∫•t ƒë√¢y n√®\n\n{links_text}"
            else:
                content = "ƒêang c·∫≠p nh·∫≠t s·∫£n ph·∫©m m·ªõi, b·∫°n quay l·∫°i sau nha"
        
        elif intent == 'promotion':
            promotions_data = self._get_relevant_promotions(message, intent)
            if promotions_data:
                promo_text = "\n".join([f"‚Ä¢ {p['code']} - Gi·∫£m {p['discount_percentage']}%" for p in promotions_data])
                content = f"Khuy·∫øn m√£i hot:\n\n{promo_text}\n\nD√πng khi thanh to√°n nha"
            else:
                content = "Hi·ªán ch∆∞a c√≥ khuy·∫øn m√£i. M√¨nh b√°o ngay khi c√≥ deal m·ªõi"
        
        elif intent == 'order_status':
            content = "B·∫°n cho m√¨nh m√£ ƒë∆°n h√†ng ƒë·ªÉ check nh√©! Ho·∫∑c ƒëƒÉng nh·∫≠p ƒë·ªÉ m√¨nh t·ª± ki·ªÉm tra"
        
        else:
            # Default fallback - Gen Z style, √≠t emoji (max 1-2)
            responses = {
                'greeting': "Ch√†o b·∫°n! M√¨nh l√† Footy üëã\n\nM√¨nh gi√∫p b·∫°n:\n‚Ä¢ T√¨m gi√†y ph√π h·ª£p\n‚Ä¢ T∆∞ v·∫•n s·∫£n ph·∫©m\n‚Ä¢ Check khuy·∫øn m√£i\n‚Ä¢ Tra ƒë∆°n h√†ng\n\nB·∫°n c·∫ßn g√¨ n√†o?",
                'order_change_request': "Ok nh√©! B·∫°n mu·ªën ƒë·ªïi g√¨? M√¨nh h·ªó tr·ª£ li·ªÅn",
                'help': "M√¨nh gi√∫p ƒë∆∞·ª£c g√¨ cho b·∫°n? T√¨m gi√†y, t∆∞ v·∫•n, khuy·∫øn m√£i hay tra ƒë∆°n ƒë·ªÅu ok nha",
                # Gen Z, kh√¥ng "em ch∆∞a hi·ªÉu", t√≠ch c·ª±c
                'unknown': "B·∫°n mu·ªën t√¨m gi√†y hay t∆∞ v·∫•n g√¨ n√†o? C·ª© h·ªèi tho·∫£i m√°i"
            }
            content = responses.get(intent, responses['unknown'])
        
        return {
            'content': content,
            'products': [],
            'promotions': []
        }
    
    def _get_fallback_response(self, intent: str, context: List[Dict] = None) -> str:
        """Ph·∫£n h·ªìi d·ª± ph√≤ng - Gen Z style, √≠t emoji (max 1-2)"""
        responses = {
            'greeting': "Ch√†o b·∫°n! M√¨nh l√† Footy üëã\n\nM√¨nh gi√∫p b·∫°n:\n‚Ä¢ T√¨m gi√†y\n‚Ä¢ T∆∞ v·∫•n\n‚Ä¢ Khuy·∫øn m√£i\n‚Ä¢ Tra ƒë∆°n\n\nB·∫°n c·∫ßn g√¨ n√†o?",
            'product_search': "B·∫°n mu·ªën t√¨m gi√†y th·∫ø n√†o? Ch·∫°y b·ªô, d·∫°o ph·ªë hay c√¥ng s·ªü?",
            'recommendation': "ƒê·ªÉ m√¨nh g·ª£i √Ω m·∫•y ƒë√¥i hot cho b·∫°n nha",
            'promotion': "ƒêang check khuy·∫øn m√£i cho b·∫°n",
            'order_status': "B·∫°n cho m√¨nh m√£ ƒë∆°n h√†ng ƒë·ªÉ check nh√©",
            'order_change_request': "B·∫°n mu·ªën ƒë·ªïi g√¨ n√†o? M√¨nh h·ªó tr·ª£ li·ªÅn",
            'help': "M√¨nh gi√∫p ƒë∆∞·ª£c g√¨ cho b·∫°n? C·ª© h·ªèi tho·∫£i m√°i",
            # Gen Z, t√≠ch c·ª±c, kh√¥ng "ch∆∞a hi·ªÉu"
            'unknown': "B·∫°n mu·ªën t√¨m gi√†y hay t∆∞ v·∫•n g√¨ n√†o? C·ª© n√≥i tho·∫£i m√°i"
        }
        return responses.get(intent, responses['unknown'])
    
    def get_cached_response(self, message: str, intent: str) -> Optional[str]:
        """L·∫•y ph·∫£n h·ªìi t·ª´ cache - Optimized for speed"""
        # T·∫°o cache key ƒë∆°n gi·∫£n h∆°n ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        cache_key = f"footy_{hash(message.lower().strip())}_{intent}"
        return cache.get(cache_key)
    
    def cache_response(self, message: str, intent: str, response: str):
        """L∆∞u ph·∫£n h·ªìi v√†o cache - Optimized for speed"""
        # T·∫°o cache key ƒë∆°n gi·∫£n h∆°n v√† tƒÉng th·ªùi gian cache
        cache_key = f"footy_{hash(message.lower().strip())}_{intent}"
        cache.set(cache_key, response, 7200)  # Cache 2 gi·ªù thay v√¨ 1 gi·ªù
    
    
    def process_message(self, message: str, user_id: str = None, session_id: str = None) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω tin nh·∫Øn ch√≠nh c·ªßa chatbot - Optimized for speed
        """
        start_time = time.time()
        
        # Validate input
        if not message or not message.strip():
            return {
                "type": "message",
                "content": "Xin l·ªói, t√¥i kh√¥ng hi·ªÉu. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√†y d√©p, khuy·∫øn m√£i, ho·∫∑c ƒë∆°n h√†ng nh√©! üòä",
                "intent": "unknown",
                "confidence": 0.0,
                "sentiment": {"sentiment": "neutral", "confidence": 0.0},
                "processing_time": 0.0,
                "timestamp": timezone.now().isoformat()
            }
        
        # L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i - T·ªëi ∆∞u
        context = self.memory.get_context(user_id or session_id) if (user_id or session_id) else []
        
        # Ph√¢n t√≠ch c·∫£m x√∫c - T·ªëi ∆∞u
        sentiment = self.sentiment_analyzer.analyze_sentiment(message)
        
        # Nh·∫≠n di·ªán √Ω ƒë·ªãnh v·ªõi confidence score - T·ªëi ∆∞u
        intent, confidence = self.detect_intent(message, context)
        
        # Check if user is asking about images
        message_lower = message.lower()
        image_related_keywords = ['h√¨nh ·∫£nh', 'hinh anh', '·∫£nh', 'anh', 'image', 'photo', 'picture', 'h√¨nh', 'hin']
        is_asking_about_images = any(keyword in message_lower for keyword in image_related_keywords)
        
        # Check if user is asking for links
        link_related_keywords = ['link', 'li√™n k·∫øt', 'lien ket', 'g·ª≠i link', 'gui link', 'cho link', 'c√≥ link', 'co link', 'link s·∫£n ph·∫©m', 'link san pham', 'ƒë∆∞·ªùng link', 'duong link', 'url']
        is_asking_for_links = any(keyword in message_lower for keyword in link_related_keywords)
        
        # Check if user is asking about images/links in context of products
        has_product_context = False
        if context and len(context) > 0:
            last_intent = context[-1].get('intent', '')
            if last_intent in ['product_search', 'recommendation']:
                has_product_context = True
        
        # Extract entities ƒë·ªÉ s·ª≠ d·ª•ng trong generate_intelligent_response
        entities = self.nlp_processor.extract_entities(message)
        
        # Update user preferences based on entities
        if user_id and entities:
            self.memory.update_user_preferences(user_id, entities)
        
        # Ki·ªÉm tra cache tr∆∞·ªõc - ∆Øu ti√™n cache ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        cached_response = self.get_cached_response(message, intent)
        if cached_response:
            # Cache ch·ªâ l∆∞u content, c·∫ßn l·∫•y th√™m products v√† promotions
            # Show products if: intent is product_search/recommendation OR asking for images/links with product context
            if is_asking_about_images and not has_product_context and intent not in ['product_search', 'recommendation']:
                products_data = []
                promotions_data = []
            elif intent in ['product_search', 'recommendation'] or (is_asking_about_images and has_product_context) or (is_asking_for_links and has_product_context):
                # If asking for images/links with product context, use last message from context
                search_message = message
                if (is_asking_about_images or is_asking_for_links) and has_product_context and context and len(context) > 0:
                    last_message = context[-1].get('message', '')
                    if last_message:
                        search_message = f"{last_message} {message}"
                products_data = self._get_relevant_products(search_message, intent if intent in ['product_search', 'recommendation'] else 'product_search')
                # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c products v√† ƒëang y√™u c·∫ßu xem h√¨nh ·∫£nh/link, th·ª≠ l·∫•y t·ª´ context
                if not products_data and (is_asking_about_images or is_asking_for_links) and context and len(context) > 0:
                    last_message = context[-1].get('message', '')
                    if last_message:
                        products_data = self._get_relevant_products(last_message, 'product_search')
                # Ch·ªâ fallback v·ªÅ top products n·∫øu KH√îNG c√≥ product context (gi·ªØ l·∫°i filters n·∫øu c√≥ context)
                if not products_data and (is_asking_about_images or is_asking_for_links) and not has_product_context:
                    products_data = self._get_relevant_products('', 'recommendation')
                elif not products_data and (is_asking_about_images or is_asking_for_links) and has_product_context:
                    logger.warning(f"No products found for image/link request with product context. Search message: {search_message}")
                
                # Th√™m links v√†o content thay v√¨ tr·∫£ v·ªÅ products array
                response_content = cached_response
                if products_data:
                    links_text = self._format_products_as_links(products_data)
                    response_content = cached_response + links_text
                
                promotions_data = self._get_relevant_promotions(search_message, intent if intent in ['product_search', 'recommendation'] else 'product_search')
            else:
                products_data = []
                promotions_data = []
                response_content = cached_response
            
            ai_response_data = {
                'content': response_content,
                'products': [],  # Kh√¥ng tr·∫£ v·ªÅ products array n·ªØa, ch·ªâ tr·∫£ v·ªÅ links trong content
                'promotions': promotions_data
            }
            logger.info(f"‚úÖ Using cached response for intent: {intent}")
        else:
            # T·∫°o ph·∫£n h·ªìi AI v·ªõi confidence - Ch·ªâ khi kh√¥ng c√≥ cache
            ai_response_data = self.generate_intelligent_response(message, intent, context, user_id, entities)
            # L∆∞u v√†o cache ch·ªâ content (tr·ª´ khi ƒëang trong multi-turn conversation)
            if not ai_response_data.get('needs_clarification', False):
                self.cache_response(message, intent, ai_response_data.get('content', ''))
            logger.info(f"üîÑ Generated new response for intent: {intent}")
        
        # T√≠nh th·ªùi gian x·ª≠ l√Ω
        processing_time = (time.time() - start_time) * 1000  # ms
        
        # Chu·∫©n b·ªã response data
        response_data = {
            "type": "message",
            "content": ai_response_data.get('content', ''),
            "products": ai_response_data.get('products', []),
            "promotions": ai_response_data.get('promotions', []),
            "intent": intent,
            "confidence": confidence,
            "sentiment": sentiment,
            "processing_time": processing_time,
            "timestamp": timezone.now().isoformat()
        }
        
        # L∆∞u v√†o memory - Ch·ªâ khi c·∫ßn thi·∫øt
        if user_id or session_id:
            self.memory.add_conversation(user_id or session_id, message, ai_response_data.get('content', ''), intent)
        
        return response_data


# Global instance
footy_ai = FootyAI()
